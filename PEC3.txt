# =============================================================================
# PRÁCTICA 3 - DEEP LEARNING: Clasificación de Granos de Polen
# Parte 1: Exploración y Análisis Exploratorio del Data
# =============================================================================

# 1. Instalación de paquetes necesarios (incluyendo keras3)
pacotes <- c("keras3", "tensorflow", "ggplot2", "gridExtra", "dplyr","tfdatasets","reshape2")
new_packages <- pacotes[!(pacotes %in% installed.packages()[,"Package"])]
if(length(new_packages)) install.packages(new_packages, dependencies = TRUE)

# 2. Cargar librerías
library(keras3)
library(tensorflow)
library(ggplot2)
library(gridExtra)
library(dplyr, warn.conflicts = FALSE)
library(tfdatasets)
library(reshape2)

# 3. Configuración inicial (Solo si no lo has hecho antes)
#install_tensorflow()

# Configurar semilla para reproducibilidad
set.seed(123L)
tensorflow::tf$random$set_seed(123L)

# =============================================================================
# 1. CARGA Y ORGANIZACIÓN DEL DATASET
# =============================================================================

# Definir rutas al dataset
# AJUSTAR ESTAS RUTAS SEGÚN TU ESTRUCTURA DE CARPETAS
# data_dir <- "path/to/your/pollen_dataset"  # Carpeta principal
data_dir <- "/Users/darolmar/Desktop/anuka1200"  # Carpeta principal
class_a_dir <- file.path(data_dir, "TipoA_Kunzea")  # Primera especie
class_b_dir <- file.path(data_dir, "TipoB_Lepto")  # Segunda especie

# Listar archivos de imágenes
images_class_a <- list.files(class_a_dir, pattern = "\\.(jpg|jpeg|png)$", 
                             full.names = TRUE, ignore.case = TRUE)
images_class_b <- list.files(class_b_dir, pattern = "\\.(jpg|jpeg|png)$", 
                             full.names = TRUE, ignore.case = TRUE)

# Información básica del dataset
cat("=== INFORMACIÓN DEL DATASET ===\n")
cat("Imágenes Clase A:", length(images_class_a), "\n")
cat("Imágenes Clase B:", length(images_class_b), "\n")
cat("Total de imágenes:", length(images_class_a) + length(images_class_b), "\n")
cat("Balance de clases:", 
    round(length(images_class_a) / (length(images_class_a) + length(images_class_b)), 3), "\n\n")

# =============================================================================
# 2. ANÁLISIS DE DIMENSIONES Y CARACTERÍSTICAS
# =============================================================================

# Función para cargar una imagen y obtener sus dimensiones
get_image_info <- function(img_path) {
  img <- image_load(img_path, color_mode = "grayscale")
  img_array <- image_to_array(img)
  return(dim(img_array))
}

# Muestrear algunas imágenes para verificar dimensiones
sample_images <- c(head(images_class_a, 5), head(images_class_b, 5))
dimensions_list <- lapply(sample_images, get_image_info)

cat("=== DIMENSIONES DE LAS IMÁGENES ===\n")
print(dimensions_list[1:3])

# Verificar si todas tienen las mismas dimensiones
unique_dims <- unique(dimensions_list)
cat("\nNúmero de dimensiones únicas:", length(unique_dims), "\n")
if(length(unique_dims) == 1) {
  cat("✓ Todas las imágenes tienen dimensiones consistentes:", 
      paste(unique_dims[[1]], collapse = " x "), "\n\n")
} else {
  cat("⚠ ADVERTENCIA: Las imágenes tienen dimensiones variables\n")
  cat("Se requerirá redimensionamiento\n\n")
}

# =============================================================================
# 3. VISUALIZACIÓN DE MUESTRAS REPRESENTATIVAS
# =============================================================================

# Función para visualizar imágenes
plot_sample_images <- function(image_paths, class_name, n_samples = 6) {
  par(mfrow = c(2, 3), mar = c(1, 1, 2, 1))
  
  sample_indices <- sample(1:length(image_paths), min(n_samples, length(image_paths)))
  
  for(i in sample_indices) {
    img <- image_load(image_paths[i], color_mode = "grayscale", target_size = c(150, 150))
    img_array <- image_to_array(img)
    img_array <- img_array / 255  # Normalizar para visualización
    
    # Convertir a formato para plot
    img_matrix <- img_array[,,1]
    
    image(t(img_matrix[nrow(img_matrix):1,]), 
          col = gray.colors(256),
          axes = FALSE,
          main = paste(class_name, "-", i))
  }
  par(mfrow = c(1, 1))
}

cat("=== VISUALIZACIÓN DE MUESTRAS ===\n")
cat("Generando visualizaciones...\n\n")

# Visualizar Clase A
plot_sample_images(images_class_a, "Clase A", 6)
# Visualizar Clase B  
plot_sample_images(images_class_b, "Clase B", 6)

# =============================================================================
# 4. ANÁLISIS ESTADÍSTICO DE INTENSIDAD DE PÍXELES
# =============================================================================

# Función para calcular estadísticas de una imagen
get_pixel_stats <- function(img_path) {
  img <- image_load(img_path, color_mode = "grayscale", target_size = c(150, 150))
  img_array <- image_to_array(img) / 255
  
  return(data.frame(
    mean_intensity = mean(img_array),
    sd_intensity = sd(img_array),
    min_intensity = min(img_array),
    max_intensity = max(img_array)
  ))
}

# Calcular estadísticas para una muestra de cada clase
n_sample <- min(50, length(images_class_a), length(images_class_b))

cat("=== ANÁLISIS DE INTENSIDAD DE PÍXELES ===\n")
cat("Calculando estadísticas para", n_sample, "imágenes por clase...\n")

stats_a <- do.call(rbind, lapply(head(images_class_a, n_sample), get_pixel_stats))
stats_a$class <- "A"

stats_b <- do.call(rbind, lapply(head(images_class_b, n_sample), get_pixel_stats))
stats_b$class <- "B"

stats_combined <- rbind(stats_a, stats_b)

# Resumen estadístico por clase
cat("\nClase A - Estadísticas de intensidad:\n")
print(summary(stats_a[, 1:4]))

cat("\nClase B - Estadísticas de intensidad:\n")
print(summary(stats_b[, 1:4]))

# Visualización comparativa
p1 <- ggplot(stats_combined, aes(x = class, y = mean_intensity, fill = class)) +
  geom_boxplot() +
  labs(title = "Distribución de Intensidad Media por Clase",
       x = "Clase", y = "Intensidad Media") +
  theme_minimal() +
  scale_fill_manual(values = c("A" = "steelblue", "B" = "coral"))

p2 <- ggplot(stats_combined, aes(x = class, y = sd_intensity, fill = class)) +
  geom_boxplot() +
  labs(title = "Distribución de Desviación Estándar por Clase",
       x = "Clase", y = "Desviación Estándar") +
  theme_minimal() +
  scale_fill_manual(values = c("A" = "steelblue", "B" = "coral"))

grid.arrange(p1, p2, ncol = 2)

# =============================================================================
# 5. PREPARACIÓN DE METADATOS PARA MODELADO
# =============================================================================

# Crear dataframe con todas las rutas y etiquetas
all_images <- c(images_class_a, images_class_b)
all_labels <- c(rep(0, length(images_class_a)), 
                rep(1, length(images_class_b)))

metadata <- data.frame(
  image_path = all_images,
  label = all_labels,
  class_name = ifelse(all_labels == 0, "Clase_A", "Clase_B"),
  stringsAsFactors = FALSE
)

# Mezclar aleatoriamente
set.seed(123L)
metadata <- metadata[sample(nrow(metadata)), ]

cat("\n=== METADATA PREPARADO ===\n")
cat("Total de imágenes procesadas:", nrow(metadata), "\n")
cat("Distribución de etiquetas:\n")
print(table(metadata$class_name))

# =============================================================================
# 6. DIVISIÓN EN CONJUNTOS DE ENTRENAMIENTO, VALIDACIÓN Y TEST
# =============================================================================

# Proporción: 70% train, 15% validation, 15% test
n_total <- nrow(metadata)
n_train <- floor(0.70 * n_total)
n_val <- floor(0.15 * n_total)
n_test <- n_total - n_train - n_val

train_data <- metadata[1:n_train, ]
val_data <- metadata[(n_train + 1):(n_train + n_val), ]
test_data <- metadata[(n_train + n_val + 1):n_total, ]

cat("\n=== DIVISIÓN DE DATOS ===\n")
cat("Entrenamiento:", nrow(train_data), "imágenes\n")
cat("Validación:", nrow(val_data), "imágenes\n")
cat("Test:", nrow(test_data), "imágenes\n\n")

# Verificar balance en cada conjunto
cat("Balance en conjunto de entrenamiento:\n")
print(prop.table(table(train_data$class_name)))
cat("\nBalance en conjunto de validación:\n")
print(prop.table(table(val_data$class_name)))
cat("\nBalance en conjunto de test:\n")
print(prop.table(table(test_data$class_name)))

# =============================================================================
# 7. GUARDAR RESULTADOS DE LA EXPLORACIÓN
# =============================================================================

# Guardar metadata para uso posterior
saveRDS(list(
  train = train_data,
  val = val_data,
  test = test_data,
  img_dims = unique_dims[[1]]
), file.path(data_dir, "dataset_metadata.rds"))

cat("\n✓ Exploración completada. Metadata guardado en 'dataset_metadata.rds'\n")
cat("\n=== CONCLUSIONES DE LA EXPLORACIÓN ===\n")
cat("1. Dataset con", n_total, "imágenes en escala de grises\n")
cat("2. Balance de clases:", 
    ifelse(abs(length(images_class_a) - length(images_class_b)) < 10, 
           "equilibrado", "ligeramente desbalanceado"), "\n")
cat("3. Imágenes con dimensiones:", paste(unique_dims[[1]][1:2], collapse = "x"), "\n")
cat("4. Preparado para iniciar modelado\n")


# =============================================================================
# Parte 2: Modelado Progresivo (NET-1 → CNN Avanzadas) - ACTUALIZADO KERAS 3
# =============================================================================

# =============================================================================
# 1. CONFIGURACIÓN GLOBAL Y CARGA DE METADATA
# =============================================================================

metadata <- readRDS(file.path(data_dir,"dataset_metadata.rds"))
train_data <- metadata$train
val_data <- metadata$val
test_data <- metadata$test

IMG_HEIGHT <- if(!is.null(metadata$img_dims[1])) as.integer(metadata$img_dims[1]) else 100L
IMG_WIDTH  <- if(!is.null(metadata$img_dims[2])) as.integer(metadata$img_dims[2]) else 100L
BATCH_SIZE <- 32L
EPOCHS <- 50L

# =============================================================================
# 2. GENERADORES DE DATOS (VERSION KERAS 3)
# =============================================================================

# En Keras 3, la normalización y el aumento se definen como capas o funciones del dataset
normalization_layer <- layer_rescaling(scale = 1/255)

# Definición del modelo usando una lista de capas
model <- keras_model_sequential(layers = list(
  # 1. Capa de entrada y normalización integrada
  layer_rescaling(scale = 1/255, input_shape = c(100L, 100L, 1L)),
  
  # 2. Primera capa convolucional
  layer_conv_2d(filters = 32L, kernel_size = c(3L, 3L), activation = "relu"),
  layer_max_pooling_2d(pool_size = c(2L, 2L)),
  
  # 3. Segunda capa convolucional
  layer_conv_2d(filters = 64L, kernel_size = c(3L, 3L), activation = "relu"),
  layer_max_pooling_2d(pool_size = c(2L, 2L)),
  
  # 4. Aplanado y capas densas
  layer_flatten(),
  layer_dense(units = 64L, activation = "relu"),
  layer_dense(units = 1L, activation = "sigmoid") # Sigmoid para clasificación binaria
))

# Ver el resumen del modelo para confirmar que todo está bien
summary(model)

data_augmentation <- keras_model_sequential(layers = list(
  layer_random_flip(mode = "horizontal_and_vertical"),
  layer_random_rotation(factor = 0.11),
  layer_random_translation(height_factor = 0.2, width_factor = 0.2),
  layer_random_zoom(height_factor = 0.2, width_factor = 0.2)
))

# Crear Datasets
# Nota: Keras 3 usa el directorio raíz y detecta subcarpetas como clases automáticamente
full_train_ds <- image_dataset_from_directory(
  data_dir,
  label_mode = "binary",
  color_mode = "grayscale",
  image_size = c(IMG_HEIGHT, IMG_WIDTH),
  batch_size = BATCH_SIZE,
  seed = 123L,
  validation_split = 0.2, # Usamos el split nativo para asegurar compatibilidad
  subset = "training"
)

full_val_ds <- image_dataset_from_directory(
  data_dir,
  label_mode = "binary",
  color_mode = "grayscale",
  image_size = c(IMG_HEIGHT, IMG_WIDTH),
  batch_size = BATCH_SIZE,
  seed = 123L,
  validation_split = 0.2,
  subset = "validation"
)

# Aplicar transformaciones (Pipeline optimizado)
train_dataset_no_aug <- full_train_ds %>% 
  tfdatasets::dataset_map(function(x, y) list(normalization_layer(x), y)) %>% 
  tfdatasets::dataset_prefetch(buffer_size = tensorflow::tf$data$AUTOTUNE)

# Dataset SIN Augmentation
train_dataset_no_aug <- full_train_ds %>% 
  tfdatasets::dataset_map(function(x, y) list(normalization_layer(x), y)) %>%
  tfdatasets::dataset_prefetch(buffer_size = tensorflow::tf$data$AUTOTUNE)

# Dataset CON Augmentation
train_dataset_aug <- full_train_ds %>% 
  tfdatasets::dataset_map(function(x, y) list(data_augmentation(normalization_layer(x), training = TRUE), y)) %>%
  tfdatasets::dataset_prefetch(buffer_size = tensorflow::tf$data$AUTOTUNE)

# Dataset de Validación 
validation_dataset <- full_val_ds %>%
  tfdatasets::dataset_map(function(x, y) list(normalization_layer(x), y)) %>%
  tfdatasets::dataset_prefetch(buffer_size = tensorflow::tf$data$AUTOTUNE)

# =============================================================================
# 3. VISUALIZAR AUGMENTATION (ACTUALIZADO)
# =============================================================================

visualize_augmentation <- function(dataset, n_samples = 9) {
  batch <- dataset %>% tfdatasets::dataset_take(1) %>% as_iterator() %>% iter_next()
  images <- batch[[1]]
  
  par(mfrow = c(3, 3), mar = c(1, 1, 2, 1))
  for(i in 1:min(n_samples, dim(images)[1])) {
    img_display <- as.array(images[i,,,1])
    image(t(img_display[nrow(img_display):1,]), 
          col = gray.colors(256), axes = FALSE,
          main = paste("Augmented", i))
  }
  par(mfrow = c(1, 1))
}

visualize_augmentation(train_dataset_aug)

# =============================================================================
# 4. MODELO 1: NET-1 (REGRESIÓN LOGÍSTICA)
# =============================================================================

model_1 <- keras_model_sequential() %>%
  layer_flatten(input_shape = c(IMG_HEIGHT, IMG_WIDTH, 1)) %>%
  layer_dense(units = 1, activation = "sigmoid")

# 1. Extraer pesos (En R, get_weights devuelve una lista)
# Los pesos están en la capa 1 (el layer_dense)
pesos_lista <- get_weights(model_1)
weights <- pesos_lista[[1]] # Matriz de pesos
bias <- pesos_lista[[2]]    # Vector de bias

# 2. Reshape a imagen 100x100
# En R, usamos la función array o simplemente cambiamos la dimensión
weight_image <- array(weights, dim = c(100, 100))

# 3. Visualizar mapa de calor
# En lugar de matplotlib, lo más sencillo en R es usar image() o lattice
image(weight_image, col = terrain.colors(100), main = "Mapa de pesos NET-1")

# O una opción más profesional con ggplot2:
library(ggplot2)
library(reshape2)

df_weights <- melt(weight_image)
ggplot(df_weights, aes(Var1, Var2, fill = value)) +
  geom_tile() +
  scale_fill_gradient2(low = "blue", mid = "white", high = "red") +
  labs(title = "Mapa de pesos aprendidos por NET-1", fill = "Peso") +
  theme_minimal()

# 4. Guardar la imagen
ggsave(file.path(data_dir, "net1_weights_heatmap.png"), dpi = 300)

model_1 %>% compile(optimizer = optimizer_adam(), loss = "binary_crossentropy", metrics = "accuracy")
history_1 <- model_1 %>% fit(train_dataset_no_aug, epochs = EPOCHS, validation_data = validation_dataset, verbose = 2)

save_model(model_1, file.path(data_dir, "model_1_net1.keras"), overwrite = TRUE)
saveRDS(history_1, file.path(data_dir, "history_1.rds"))


# =============================================================================
# 5. MODELO 2: RED CON CAPAS OCULTAS
# =============================================================================

# Modelo 2 corregido
model_2 <- keras_model_sequential() %>%
  layer_flatten(input_shape = c(IMG_HEIGHT, IMG_WIDTH, 1)) %>%
  layer_dense(units = 256L, activation = "relu") %>% # <-- Asegúrate de que este %>% esté ahí
  layer_dropout(rate = 0.3) %>%                      # <-- ¡AQUÍ suele faltar el %>%!
  layer_dense(units = 1L, activation = "sigmoid")    # Capa final

model_2 %>% compile(optimizer = optimizer_adam(), loss = "binary_crossentropy", metrics = "accuracy")

history_2 <- model_2 %>% fit(train_dataset_no_aug, epochs = EPOCHS, validation_data = validation_dataset, verbose = 2)

save_model(model_2, file.path(data_dir, "model_2_mlp.keras"), overwrite = TRUE)
saveRDS(history_2, file.path(data_dir, "history_2.rds"))



# =============================================================================
# 6. MODELO 3: CNN BASE (CON AUGMENTATION)
# =============================================================================

model_3 <- keras_model_sequential() %>%
  layer_conv_2d(filters = 32, kernel_size = c(3, 3), activation = "relu", input_shape = c(IMG_HEIGHT, IMG_WIDTH, 1)) %>%
  layer_max_pooling_2d() %>%
  layer_conv_2d(filters = 64, kernel_size = c(3, 3), activation = "relu") %>%
  layer_max_pooling_2d() %>%
  layer_flatten() %>%
  layer_dense(units = 128, activation = "relu") %>%
  layer_dense(units = 1, activation = "sigmoid")

model_3 %>% compile(optimizer = optimizer_adam(), loss = "binary_crossentropy", metrics = "accuracy")
save_model(model_3, file.path(data_dir, "model_3_cnn_base.keras"), overwrite = TRUE)

history_3 <- model_3 %>% fit(train_dataset_aug, epochs = EPOCHS, validation_data = validation_dataset, verbose = 2)
saveRDS(history_3, file.path(data_dir, "history_3.rds"))

# MODELO 3b: CNN Base SIN AUGMENTATION (para comparación)
model_3_no_aug <- keras_model_sequential() %>%
  layer_conv_2d(filters = 32, kernel_size = c(3, 3), activation = "relu", 
                input_shape = c(IMG_HEIGHT, IMG_WIDTH, 1)) %>%
  layer_max_pooling_2d() %>%
  layer_conv_2d(filters = 64, kernel_size = c(3, 3), activation = "relu") %>%
  layer_max_pooling_2d() %>%
  layer_flatten() %>%
  layer_dense(units = 128, activation = "relu") %>%
  layer_dense(units = 1, activation = "sigmoid")

model_3_no_aug %>% compile(
  optimizer = optimizer_adam(), 
  loss = "binary_crossentropy", 
  metrics = "accuracy"
)

history_3_no_aug <- model_3_no_aug %>% fit(
  train_dataset_no_aug,  # ← SIN augmentation
  epochs = EPOCHS, 
  validation_data = validation_dataset, 
  verbose = 2
)

saveRDS(history_3_no_aug, file.path(data_dir, "history_3_no_aug.rds"))

# =============================================================================
# 7. MODELO 4: CNN CON BATCH NORMALIZATION
# =============================================================================

model_4  <- keras_model_sequential() %>%
  layer_conv_2d(32, c(3,3), activation = "relu", 
                input_shape = c(IMG_HEIGHT, IMG_WIDTH, 1)) %>%
  layer_batch_normalization() %>%
  layer_max_pooling_2d() %>%
  
  layer_conv_2d(64, c(3,3), activation = "relu") %>%
  layer_batch_normalization() %>%
  layer_max_pooling_2d() %>%
  
  layer_conv_2d(128, c(3,3), activation = "relu") %>%
  layer_batch_normalization() %>%
  layer_max_pooling_2d() %>%
  
  layer_flatten() %>%
  layer_dense(128, activation = "relu") %>%
  layer_dropout(0.5) %>%
  layer_dense(1, activation = "sigmoid")

model_4 %>% compile(
  optimizer = optimizer_adam(learning_rate = 0.0001),  # LR 10x menor
  loss = "binary_crossentropy", 
  metrics = "accuracy"
)

history_4 <- model_4 %>% fit(
  train_dataset_aug,
  epochs = EPOCHS,
  validation_data = validation_dataset,
  verbose = 2
)
save_model(model_4, file.path(data_dir, "model_4.keras"), overwrite = TRUE)
saveRDS(history_4, file.path(data_dir, "history_4.rds"))


# =============================================================================
# 8. MODELO 5: CNN CON GAP
# =============================================================================

model_5 <- keras_model_sequential() %>%
  layer_conv_2d(32, c(5,5), activation = "relu",  # Kernel 5x5
                input_shape = c(IMG_HEIGHT, IMG_WIDTH, 1)) %>%
  layer_max_pooling_2d() %>%
  layer_dropout(0.25) %>%
  
  layer_conv_2d(64, c(3,3), activation = "relu") %>%
  layer_max_pooling_2d() %>%
  layer_dropout(0.25) %>%
  
  layer_conv_2d(128, c(3,3), activation = "relu") %>%
  layer_max_pooling_2d() %>%
  layer_dropout(0.25) %>%
  
  layer_flatten() %>%
  layer_dense(256, activation = "relu") %>%
  layer_dropout(0.5) %>%
  layer_dense(128, activation = "relu") %>%
  layer_dropout(0.5) %>%
  layer_dense(1, activation = "sigmoid")

model_5 %>% compile(
  optimizer = optimizer_adam(learning_rate = 0.0001),
  loss = "binary_crossentropy", 
  metrics = "accuracy"
)

history_5 <- model_5 %>% fit(
  train_dataset_aug,
  epochs = EPOCHS,
  validation_data = validation_dataset,
  verbose = 2
)
save_model(model_5, file.path(data_dir, "model_5.keras"), overwrite = TRUE)
saveRDS(history_5, file.path(data_dir, "history_5.rds"))



# =============================================================================
# 9. COMPARACIÓN FINAL
# =============================================================================

results <- data.frame(
  Modelo = c("NET-1", "MLP", "CNN Base", "CNN + BN", "CNN + GAP"),
  Val_Accuracy = c(
    tail(history_1$metrics$val_accuracy, 1),
    tail(history_2$metrics$val_accuracy, 1),
    tail(history_3$metrics$val_accuracy, 1),
    tail(history_4$metrics$val_accuracy, 1),
    tail(history_5$metrics$val_accuracy, 1)
  )
)
print(results)

# =============================================================================
# Parte 3: Análisis Crítico, Visualizaciones y Generación de Figuras
# =============================================================================

# =============================================================================
# 1. GRÁFICA COMPARATIVA DE APRENDIZAJE (Figura estilo 11.11 Hastie)
# =============================================================================

# Cargar historiales de entrenamiento
history_1 <- readRDS(file.path(data_dir,"history_1.rds"))
history_2 <- readRDS(file.path(data_dir,"history_2.rds"))
history_3 <- readRDS(file.path(data_dir,"history_3.rds"))
history_4 <- readRDS(file.path(data_dir,"history_4.rds"))
history_5 <- readRDS(file.path(data_dir,"history_5.rds"))

# Función para extraer métricas en formato tidy
extract_metrics <- function(history, model_name) {
  epochs <- seq_along(history$metrics$loss)
  
  data.frame(
    epoch = epochs,
    model = model_name,
    train_loss = history$metrics$loss,
    val_loss = history$metrics$val_loss,
    train_acc = history$metrics$accuracy,
    val_acc = history$metrics$val_accuracy
  )
}

# Consolidar todos los modelos
all_metrics <- rbind(
  extract_metrics(history_1, "NET-1 (sin capa oculta)"),
  extract_metrics(history_2, "MLP (con capas ocultas)"),
  extract_metrics(history_3, "CNN Base"),
  extract_metrics(history_4, "CNN + Batch Norm"),
  extract_metrics(history_5, "CNN + GAP")
)

# GRÁFICA 1: Loss de Validación (principal para la memoria)
plot_val_loss <- ggplot(all_metrics, aes(x = epoch, y = val_loss, 
                                          color = model, linetype = model)) +
  geom_line(size = 1) +
  labs(
    title = "Evolución del Loss en Validación",
    subtitle = "Comparación de los 5 modelos (menor es mejor)",
    x = "Época",
    y = "Binary Crossentropy Loss",
    color = "Modelo",
    linetype = "Modelo"
  ) +
  theme_minimal(base_size = 12) +
  theme(
    legend.position = "bottom",
    legend.direction = "vertical",
    plot.title = element_text(face = "bold", size = 14),
    panel.grid.minor = element_blank()
  ) +
  scale_color_brewer(palette = "Set1")

print(plot_val_loss)
ggsave( filename = file.path(data_dir, "figura_loss_validacion.png"), plot = plot_val_loss, width = 10, height = 6, dpi = 300 )

# GRÁFICA 2: Accuracy de Validación
plot_val_acc <- ggplot(all_metrics, aes(x = epoch, y = val_acc, 
                                         color = model, linetype = model)) +
  geom_line(size = 1) +
  labs(
    title = "Evolución del Accuracy en Validación",
    subtitle = "Comparación de los 5 modelos (mayor es mejor)",
    x = "Época",
    y = "Accuracy",
    color = "Modelo",
    linetype = "Modelo"
  ) +
  theme_minimal(base_size = 12) +
  theme(
    legend.position = "bottom",
    legend.direction = "vertical",
    plot.title = element_text(face = "bold", size = 14),
    panel.grid.minor = element_blank()
  ) +
  scale_color_brewer(palette = "Set1") +
  ylim(0.5, 1.0)

print(plot_val_acc)
ggsave( filename = file.path(data_dir, "figura_accuracy_validacion.png"), plot = plot_val_acc, width = 10, height = 6, dpi = 300 )

# GRÁFICA 3: Train vs Validation (para detectar overfitting)
# Seleccionar el mejor modelo (ej: modelo 5)
best_model_data <- all_metrics %>% 
  filter(model == "CNN + GAP") %>%
  select(epoch, train_loss, val_loss, train_acc, val_acc) %>%
  melt(id.vars = "epoch")

# Separar loss y accuracy
overfitting_loss <- best_model_data %>%
  filter(variable %in% c("train_loss", "val_loss"))

overfitting_acc <- best_model_data %>%
  filter(variable %in% c("train_acc", "val_acc"))

plot_overfitting <- ggplot(overfitting_loss, aes(x = epoch, y = value, 
                                                  color = variable, linetype = variable)) +
  geom_line(size = 1.2) +
  labs(
    title = "Análisis de Overfitting: CNN + GAP",
    subtitle = "Comparación Train vs Validación (Loss)",
    x = "Época",
    y = "Binary Crossentropy Loss",
    color = "Conjunto",
    linetype = "Conjunto"
  ) +
  theme_minimal(base_size = 12) +
  scale_color_manual(
    values = c("train_loss" = "blue", "val_loss" = "red"),
    labels = c("Entrenamiento", "Validación")
  ) +
  scale_linetype_manual(
    values = c("train_loss" = "solid", "val_loss" = "dashed"),
    labels = c("Entrenamiento", "Validación")
  ) +
  theme(legend.position = "bottom")

print(plot_overfitting)
ggsave(
  filename = file.path(data_dir, "figura_overfitting_analysis.png"), 
  plot = plot_val_loss, 
  width = 10, 
  height = 6, 
  dpi = 300
)
cat("✓ Gráficas comparativas generadas\n\n")

# =============================================================================
# 2. ANÁLISIS DE PESOS: Primera Capa Convolucional
# =============================================================================

cat("=== VISUALIZACIÓN DE PESOS (Filtros Conv) ===\n")

# 1. Cargar modelo CNN base (modelo 3) # 
model_cnn <- load_model(file.path(data_dir,"model_3_cnn_base.keras"))
# 2. Extraer la primera capa CONVOLUCIONAL (buscándola por nombre o tipo para evitar errores de índice) 
# Si sabes que es la primera capa, usa index = 1L (con L de integer) 
first_conv_layer <- get_layer(model_cnn, index = 1L) 
# 3. Extraer pesos 
weights <- get_weights(first_conv_layer)
filters <- weights[[1]] # El primer elemento son los pesos, el segundo los bias 
# 4. Mostrar información
cat("Dimensiones de los filtros:", paste(dim(filters), collapse = " x "), "\n")
cat("Número de filtros en primera capa:", dim(filters)[4], "\n")

# Función para visualizar filtros
plot_conv_filters <- function(filters, n_filters = 32, ncol = 8) {
  # Normalizar filtros para visualización
  f_min <- min(filters)
  f_max <- max(filters)
  filters_norm <- (filters - f_min) / (f_max - f_min)
  
  n_filters <- min(n_filters, dim(filters)[4])
  nrow <- ceiling(n_filters / ncol)
  
  par(mfrow = c(nrow, ncol), mar = c(0.5, 0.5, 1, 0.5))
  
  for(i in 1:n_filters) {
    filter_img <- filters_norm[,,1,i]
    image(t(filter_img[nrow(filter_img):1,]), 
          col = gray.colors(256),
          axes = FALSE,
          main = paste("F", i, sep = ""),
          cex.main = 0.8)
  }
  par(mfrow = c(1, 1))
}

# Visualizar los 32 filtros de la primera capa
png(file.path(data_dir, "figura_filtros_conv1.png"), width = 2400, height = 1200, res = 300)

plot_conv_filters(filters, n_filters = 32, ncol = 8)
dev.off()

cat("✓ Filtros de convolución visualizados y guardados\n\n")

# Estadísticas de los filtros
cat("Análisis estadístico de los filtros:\n")
cat("Media de pesos:", mean(filters), "\n")
cat("Desviación estándar:", sd(filters), "\n")
cat("Rango:", range(filters), "\n\n")

# =============================================================================
# 3. VISUALIZACIÓN DE MAPAS DE CARACTERÍSTICAS (Feature Maps)
# =============================================================================

cat("=== MAPAS DE CARACTERÍSTICAS ===\n")

# Cargar metadata y seleccionar una imagen de test
metadata <- readRDS(file.path(data_dir,"dataset_metadata.rds"))
test_data <- metadata$test

# Seleccionar una imagen de cada clase para análisis
sample_class_a <- test_data %>% filter(label == 0) %>% slice(1)
sample_class_b <- test_data %>% filter(label == 1) %>% slice(1)

# Función para extraer mapas de características
get_feature_maps <- function(model, image_path, layer_indices) {
  # 1. Cargar y preparar la imagen
  img <- image_load(image_path, target_size = c(100, 100), color_mode = "grayscale")
  img_array <- image_to_array(img)
  img_array <- array_reshape(img_array, c(1, 100, 100, 1))
  img_array <- img_array / 255 # Normalización manual
  
  # 2. Extraer las salidas de las capas deseadas
  # Cambiamos 'model$input' por 'model$inputs' para Keras 3
  layer_outputs <- lapply(layer_indices, function(i) model$layers[[i]]$output)
  
  # 3. Crear un modelo intermedio que devuelva los mapas de características
  activation_model <- keras_model(inputs = model$inputs, outputs = layer_outputs)
  
  # 4. Obtener las activaciones
  activations <- predict(activation_model, img_array)
  
  return(activations)
}

# Extraer feature maps para una imagen de Clase A
cat("Extrayendo feature maps para Clase A...\n")
# 1. Asegurar que las dimensiones son enteros (L)
img_size_dims <- c(1L, 100L, 100L, 1L) 

# 2. Forzar la construcción física del modelo
model_cnn$build(input_shape = img_size_dims)

# 3. Crear un tensor de prueba y pasarlo por el modelo 
# Usamos predict() porque es la forma más oficial de 'llamar' al modelo
dummy_data <- array(0, dim = img_size_dims)
predict(model_cnn, dummy_data) 

# 4. Ahora intenta de nuevo la extracción
feature_maps_a <- get_feature_maps(model_cnn, 
                                   sample_class_a$image_path, 
                                   layer_indices = c(1, 3, 5))

# Función para visualizar feature maps de una capa
plot_feature_maps <- function(activation, layer_name, n_features = 16, ncol = 4) {
  n_features <- min(n_features, dim(activation)[4])
  nrow <- ceiling(n_features / ncol)
  
  par(mfrow = c(nrow, ncol), mar = c(0.5, 0.5, 1.5, 0.5))
  
  for(i in 1:n_features) {
    feature <- activation[1,,,i]
    
    # Normalizar para visualización
    feature <- (feature - min(feature)) / (max(feature) - min(feature))
    
    image(t(feature[nrow(feature):1,]), 
          col = gray.colors(256),
          axes = FALSE,
          main = paste(layer_name, "- Map", i),
          cex.main = 0.7)
  }
  par(mfrow = c(1, 1))
}

# Visualizar mapas de la primera capa convolucional
png(file.path(data_dir, "figura_feature_maps_conv1.png"), width = 2000, height = 2000, res = 300)
plot_feature_maps(feature_maps_a$activations[[1]], "Conv1 (32 filtros)", 
                  n_features = 16, ncol = 4)
dev.off()

# Visualizar mapas de la segunda capa convolucional
png(file.path(data_dir, "figura_feature_maps_conv2.png"), width = 2000, height = 2000, res = 300)

plot_feature_maps(feature_maps_a$activations[[2]], "Conv2 (64 filtros)", 
                  n_features = 16, ncol = 4)
dev.off()

# Visualizar mapas de la tercera capa convolucional
png(file.path(data_dir, "figura_feature_maps_conv3.png"), width = 2000, height = 2000, res = 300)

plot_feature_maps(feature_maps_a$activations[[3]], "Conv3 (128 filtros)", 
                  n_features = 16, ncol = 4)
dev.off()

cat("✓ Feature maps generados para todas las capas convolucionales\n\n")

# =============================================================================
# 4. COMPARACIÓN DE FEATURE MAPS: Clase A vs Clase B
# =============================================================================

cat("Extrayendo feature maps para Clase B (comparación)...\n")
feature_maps_b <- get_feature_maps(model_cnn, sample_class_b$image_path, 
                                   layer_indices = c(1, 3, 5))

# Visualización comparativa: misma capa, ambas clases
png("figura_comparacion_clases.png", width = 3000, height = 1500, res = 300)
par(mfrow = c(2, 8), mar = c(0.5, 0.5, 1.5, 0.5))

# Primera fila: Clase A
for(i in 1:8) {
  feature_a <- feature_maps_a$activations[[1]][1,,,i]
  feature_a <- (feature_a - min(feature_a)) / (max(feature_a) - min(feature_a))
  image(t(feature_a[nrow(feature_a):1,]), 
        col = gray.colors(256),
        axes = FALSE,
        main = paste("Clase A - F", i),
        cex.main = 0.7)
}

# Segunda fila: Clase B
for(i in 1:8) {
  feature_b <- feature_maps_b$activations[[1]][1,,,i]
  feature_b <- (feature_b - min(feature_b)) / (max(feature_b) - min(feature_b))
  image(t(feature_b[nrow(feature_b):1,]), 
        col = gray.colors(256),
        axes = FALSE,
        main = paste("Clase B - F", i),
        cex.main = 0.7)
}

par(mfrow = c(1, 1))
dev.off()

cat("✓ Comparación de feature maps entre clases completada\n\n")

# =============================================================================
# 5. TABLA RESUMEN DE RESULTADOS FINALES
# =============================================================================

cat("=== TABLA RESUMEN FINAL ===\n\n")

# Cargar todos los historiales
histories <- list(history_1, history_2, history_3, history_4, history_5)
model_names <- c("NET-1", "MLP", "CNN Base", "CNN + BN", "CNN + GAP")

# Calcular métricas finales
final_results <- data.frame(
  Modelo = model_names,
  Params = c(10001, 3383873, 2473729, 2530753, 558721),  # Aproximado, ajustar
  Train_Acc = sapply(histories, function(h) round(tail(h$metrics$accuracy, 1), 4)),
  Val_Acc = sapply(histories, function(h) round(tail(h$metrics$val_accuracy, 1), 4)),
  Train_Loss = sapply(histories, function(h) round(tail(h$metrics$loss, 1), 4)),
  Val_Loss = sapply(histories, function(h) round(tail(h$metrics$val_loss, 1), 4)),
  Gap = sapply(histories, function(h) {
    round(tail(h$metrics$accuracy, 1) - tail(h$metrics$val_accuracy, 1), 4)
  })
)

print(final_results)

# Guardar tabla en CSV para incluir en memoria
write.csv(
  final_results, 
  file = file.path(data_dir, "tabla_resultados_finales.csv"), 
  row.names = FALSE
)
# Identificar mejor modelo
best_model_idx <- which.max(final_results$Val_Acc)
cat("\n✓ MEJOR MODELO:", model_names[best_model_idx], "\n")
cat("  - Val Accuracy:", final_results$Val_Acc[best_model_idx], "\n")
cat("  - Gap (overfitting):", final_results$Gap[best_model_idx], "\n\n")

# =============================================================================
# 6. ANÁLISIS DE IMPACTO DE DATA AUGMENTATION
# =============================================================================

cat("=== IMPACTO DE DATA AUGMENTATION ===\n")

# Entrenar CNN Base SIN augmentation para comparar
cat("Nota: Para análisis completo de augmentation, entrenar modelo 3\n")
cat("      una vez sin augmentation y comparar resultados.\n\n")

# Comparación cualitativa (basada en gap train-val)
augmentation_analysis <- data.frame(
  Aspecto = c("Overfitting (Gap)", "Val Accuracy", "Convergencia"),
  Sin_Aug = c("Alto", "Puede ser mayor inicialmente", "Más rápida"),
  Con_Aug = c("Bajo", "Más estable y generalizable", "Más lenta pero robusta")
)

print(augmentation_analysis)

cat("\n✓ Análisis completado. Todas las figuras guardadas.\n")
cat("\nARCHIVOS GENERADOS:\n")
cat("  - figura_loss_validacion.png\n")
cat("  - figura_accuracy_validacion.png\n")
cat("  - figura_overfitting_analysis.png\n")
cat("  - figura_filtros_conv1.png\n")
cat("  - figura_feature_maps_conv1.png\n")
cat("  - figura_feature_maps_conv2.png\n")
cat("  - figura_feature_maps_conv3.png\n")
cat("  - figura_comparacion_clases.png\n")
cat("  - tabla_resultados_finales.csv\n")

# =============================================================================
# GRÁFICA COMPARATIVA: MODELOS 1, 2 Y 3
# Análisis de progresión arquitectónica (NET-1 → MLP → CNN)
# =============================================================================

library(ggplot2)
library(dplyr)
library(reshape2)
library(gridExtra)

# Configurar directorio
data_dir <- "/Users/darolmar/Desktop/anuka1200"

# =============================================================================
# 1. CARGAR HISTORIALES DE ENTRENAMIENTO
# =============================================================================

cat("Cargando historiales de entrenamiento...\n")

history_1 <- readRDS(file.path(data_dir, "history_1.rds"))
history_2 <- readRDS(file.path(data_dir, "history_2.rds"))
history_3_no_aug <- readRDS(file.path(data_dir, "history_3_no_aug.rds"))
history_3_aug <- readRDS(file.path(data_dir, "history_3.rds"))

# Función para extraer métricas en formato tidy
extract_metrics <- function(history, model_name) {
  epochs <- seq_along(history$metrics$loss)
  
  data.frame(
    epoch = epochs,
    model = model_name,
    train_loss = history$metrics$loss,
    val_loss = history$metrics$val_loss,
    train_acc = history$metrics$accuracy,
    val_acc = history$metrics$val_accuracy
  )
}

# Consolidar modelos 1, 2, 3 (sin augmentation) y 3 (con augmentation)
all_metrics <- rbind(
  extract_metrics(history_1, "Modelo 1: NET-1"),
  extract_metrics(history_2, "Modelo 2: MLP"),
  extract_metrics(history_3_no_aug, "Modelo 3: CNN (sin aug)"),
  extract_metrics(history_3_aug, "Modelo 3: CNN (con aug)")
)

cat("✓ Historiales cargados\n\n")

# =============================================================================
# 2. GRÁFICA PRINCIPAL: ACCURACY DE VALIDACIÓN (Progresión arquitectónica)
# =============================================================================

cat("Generando gráfica de accuracy en validación...\n")

# Paleta de colores académica
colores <- c(
  "Modelo 1: NET-1" = "#E41A1C",           # Rojo
  "Modelo 2: MLP" = "#377EB8",             # Azul
  "Modelo 3: CNN (sin aug)" = "#4DAF4A",   # Verde oscuro
  "Modelo 3: CNN (con aug)" = "#984EA3"    # Púrpura
)

plot_accuracy_progresion <- ggplot(all_metrics, 
                                   aes(x = epoch, y = val_acc, 
                                       color = model, linetype = model)) +
  geom_line(size = 1.2) +
  
  # Línea horizontal en el mejor resultado (para referencia)
  geom_hline(yintercept = 0.9271, linetype = "dashed", 
             color = "gray30", alpha = 0.5) +
  annotate("text", x = 45, y = 0.935, 
           label = "Mejor resultado: 92.71%", 
           size = 3.5, color = "gray30") +
  
  # Estilo y etiquetas
  labs(
    title = "Progresión Arquitectónica: NET-1 → MLP → CNN",
    subtitle = "Evolución del accuracy de validación durante entrenamiento",
    x = "Época",
    y = "Validation Accuracy",
    color = "Arquitectura",
    linetype = "Arquitectura"
  ) +
  
  # Tema académico
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(face = "bold", size = 16, hjust = 0.5),
    plot.subtitle = element_text(size = 12, hjust = 0.5, color = "gray40"),
    legend.position = "bottom",
    legend.direction = "vertical",
    legend.title = element_text(face = "bold"),
    panel.grid.minor = element_blank(),
    panel.grid.major = element_line(color = "gray90"),
    axis.title = element_text(face = "bold")
  ) +
  
  # Colores personalizados
  scale_color_manual(values = colores) +
  scale_linetype_manual(values = c(
    "Modelo 1: NET-1" = "solid",
    "Modelo 2: MLP" = "solid",
    "Modelo 3: CNN (sin aug)" = "solid",
    "Modelo 3: CNN (con aug)" = "dashed"
  )) +
  
  # Escala del eje Y
  scale_y_continuous(
    limits = c(0.5, 1.0),
    breaks = seq(0.5, 1.0, 0.1),
    labels = scales::percent_format(accuracy = 1)
  ) +
  
  # Escala del eje X
  scale_x_continuous(breaks = seq(0, 50, 10))

print(plot_accuracy_progresion)

# Guardar en alta resolución
ggsave(
  filename = file.path(data_dir, "figura_comparativa_modelos_123.png"),
  plot = plot_accuracy_progresion,
  width = 12,
  height = 7,
  dpi = 300
)

cat("✓ Gráfica principal guardada\n\n")

# =============================================================================
# 3. GRÁFICA SECUNDARIA: LOSS DE VALIDACIÓN
# =============================================================================

cat("Generando gráfica de loss en validación...\n")

plot_loss_progresion <- ggplot(all_metrics, 
                               aes(x = epoch, y = val_loss, 
                                   color = model, linetype = model)) +
  geom_line(size = 1.2) +
  
  labs(
    title = "Progresión del Loss en Validación",
    subtitle = "Binary Crossentropy Loss (menor es mejor)",
    x = "Época",
    y = "Validation Loss",
    color = "Arquitectura",
    linetype = "Arquitectura"
  ) +
  
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(face = "bold", size = 16, hjust = 0.5),
    plot.subtitle = element_text(size = 12, hjust = 0.5, color = "gray40"),
    legend.position = "bottom",
    legend.direction = "vertical",
    legend.title = element_text(face = "bold"),
    panel.grid.minor = element_blank(),
    panel.grid.major = element_line(color = "gray90"),
    axis.title = element_text(face = "bold")
  ) +
  
  scale_color_manual(values = colores) +
  scale_linetype_manual(values = c(
    "Modelo 1: NET-1" = "solid",
    "Modelo 2: MLP" = "solid",
    "Modelo 3: CNN (sin aug)" = "solid",
    "Modelo 3: CNN (con aug)" = "dashed"
  )) +
  
  scale_x_continuous(breaks = seq(0, 50, 10))

print(plot_loss_progresion)

ggsave(
  filename = file.path(data_dir, "figura_comparativa_loss_123.png"),
  plot = plot_loss_progresion,
  width = 12,
  height = 7,
  dpi = 300
)

cat("✓ Gráfica de loss guardada\n\n")

# =============================================================================
# 4. GRÁFICA COMPARATIVA: TRAIN VS VALIDATION (Panel múltiple)
# =============================================================================

cat("Generando panel comparativo train vs validation...\n")

# Preparar datos para facet (solo modelos principales)
modelos_principales <- all_metrics %>%
  filter(model %in% c("Modelo 1: NET-1", 
                      "Modelo 2: MLP", 
                      "Modelo 3: CNN (sin aug)"))

# Convertir a formato largo para train y val
datos_largo <- modelos_principales %>%
  select(epoch, model, train_acc, val_acc) %>%
  melt(id.vars = c("epoch", "model"),
       variable.name = "conjunto",
       value.name = "accuracy")

# Renombrar para claridad
datos_largo$conjunto <- factor(
  datos_largo$conjunto,
  levels = c("train_acc", "val_acc"),
  labels = c("Entrenamiento", "Validación")
)

plot_train_val_panel <- ggplot(datos_largo, 
                               aes(x = epoch, y = accuracy, 
                                   color = conjunto, linetype = conjunto)) +
  geom_line(size = 1) +
  facet_wrap(~ model, ncol = 1) +
  
  labs(
    title = "Análisis de Overfitting: Train vs Validation",
    subtitle = "Comparación por modelo",
    x = "Época",
    y = "Accuracy",
    color = "Conjunto",
    linetype = "Conjunto"
  ) +
  
  theme_minimal(base_size = 12) +
  theme(
    plot.title = element_text(face = "bold", size = 14, hjust = 0.5),
    plot.subtitle = element_text(size = 11, hjust = 0.5, color = "gray40"),
    legend.position = "bottom",
    strip.text = element_text(face = "bold", size = 11),
    strip.background = element_rect(fill = "gray95", color = NA),
    panel.grid.minor = element_blank(),
    axis.title = element_text(face = "bold")
  ) +
  
  scale_color_manual(values = c("Entrenamiento" = "#377EB8", 
                                 "Validación" = "#E41A1C")) +
  scale_linetype_manual(values = c("Entrenamiento" = "solid", 
                                   "Validación" = "dashed")) +
  
  scale_y_continuous(
    limits = c(0.5, 1.0),
    breaks = seq(0.5, 1.0, 0.1),
    labels = scales::percent_format(accuracy = 1)
  ) +
  
  scale_x_continuous(breaks = seq(0, 50, 10))

print(plot_train_val_panel)

ggsave(
  filename = file.path(data_dir, "figura_train_val_panel_123.png"),
  plot = plot_train_val_panel,
  width = 10,
  height = 10,
  dpi = 300
)

cat("✓ Panel train vs validation guardado\n\n")

# =============================================================================
# 5. TABLA COMPARATIVA DE RESULTADOS FINALES
# =============================================================================

cat("Generando tabla comparativa de resultados finales...\n")

# Extraer métricas finales (última época)
resultados_finales <- data.frame(
  Modelo = c("NET-1", "MLP", "CNN (sin aug)", "CNN (con aug)"),
  
  Train_Acc = c(
    round(tail(history_1$metrics$accuracy, 1), 4),
    round(tail(history_2$metrics$accuracy, 1), 4),
    round(tail(history_3_no_aug$metrics$accuracy, 1), 4),
    round(tail(history_3_aug$metrics$accuracy, 1), 4)
  ),
  
  Val_Acc = c(
    round(tail(history_1$metrics$val_accuracy, 1), 4),
    round(tail(history_2$metrics$val_accuracy, 1), 4),
    round(tail(history_3_no_aug$metrics$val_accuracy, 1), 4),
    round(tail(history_3_aug$metrics$val_accuracy, 1), 4)
  ),
  
  Val_Loss = c(
    round(tail(history_1$metrics$val_loss, 1), 4),
    round(tail(history_2$metrics$val_loss, 1), 4),
    round(tail(history_3_no_aug$metrics$val_loss, 1), 4),
    round(tail(history_3_aug$metrics$val_loss, 1), 4)
  ),
  
  Parametros = c(
    "10,001",
    "3,383,873",
    "2,473,729",
    "2,473,729"
  )
)

# Calcular gap
resultados_finales$Gap <- resultados_finales$Train_Acc - resultados_finales$Val_Acc

# Calcular mejora sobre NET-1
resultados_finales$Mejora_vs_NET1 <- 
  (resultados_finales$Val_Acc - resultados_finales$Val_Acc[1]) * 100

# Imprimir tabla
cat("\n=== TABLA COMPARATIVA DE RESULTADOS ===\n\n")
print(resultados_finales)

# Guardar tabla
write.csv(
  resultados_finales,
  file.path(data_dir, "tabla_comparativa_modelos_123.csv"),
  row.names = FALSE
)

cat("\n✓ Tabla guardada en CSV\n\n")

# =============================================================================
# 6. GRÁFICA DE BARRAS: COMPARACIÓN FINAL DE ACCURACY
# =============================================================================

cat("Generando gráfica de barras comparativa...\n")

# Preparar datos para barras
datos_barras <- resultados_finales %>%
  select(Modelo, Train_Acc, Val_Acc) %>%
  melt(id.vars = "Modelo",
       variable.name = "Conjunto",
       value.name = "Accuracy")

# Renombrar
datos_barras$Conjunto <- factor(
  datos_barras$Conjunto,
  levels = c("Train_Acc", "Val_Acc"),
  labels = c("Entrenamiento", "Validación")
)

plot_barras_comparativo <- ggplot(datos_barras, 
                                  aes(x = Modelo, y = Accuracy, 
                                      fill = Conjunto)) +
  geom_bar(stat = "identity", position = "dodge", width = 0.7) +
  
  # Añadir valores sobre las barras
  geom_text(aes(label = sprintf("%.2f%%", Accuracy * 100)),
            position = position_dodge(width = 0.7),
            vjust = -0.5,
            size = 3.5) +
  
  # Línea horizontal en 92.71% (mejor resultado)
  geom_hline(yintercept = 0.9271, linetype = "dashed", 
             color = "gray30", alpha = 0.5) +
  
  labs(
    title = "Comparación de Accuracy: Modelos 1, 2 y 3",
    subtitle = "Resultados finales en entrenamiento y validación",
    x = "Modelo",
    y = "Accuracy",
    fill = "Conjunto"
  ) +
  
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(face = "bold", size = 16, hjust = 0.5),
    plot.subtitle = element_text(size = 12, hjust = 0.5, color = "gray40"),
    legend.position = "bottom",
    legend.title = element_text(face = "bold"),
    axis.title = element_text(face = "bold"),
    axis.text.x = element_text(angle = 0, hjust = 0.5)
  ) +
  
  scale_fill_manual(values = c("Entrenamiento" = "#377EB8", 
                                "Validación" = "#E41A1C")) +
  
  scale_y_continuous(
    limits = c(0, 1.05),
    breaks = seq(0, 1.0, 0.2),
    labels = scales::percent_format(accuracy = 1)
  )

print(plot_barras_comparativo)

ggsave(
  filename = file.path(data_dir, "figura_barras_comparativa_123.png"),
  plot = plot_barras_comparativo,
  width = 10,
  height = 7,
  dpi = 300
)

cat("✓ Gráfica de barras guardada\n\n")

# =============================================================================
# 7. RESUMEN Y CONCLUSIONES
# =============================================================================

cat("=======================================================\n")
cat("✓ ANÁLISIS COMPARATIVO COMPLETADO\n")
cat("=======================================================\n\n")

cat("ARCHIVOS GENERADOS:\n")
cat("1. figura_comparativa_modelos_123.png - Accuracy en validación\n")
cat("2. figura_comparativa_loss_123.png - Loss en validación\n")
cat("3. figura_train_val_panel_123.png - Panel train vs val\n")
cat("4. figura_barras_comparativa_123.png - Comparación final\n")
cat("5. tabla_comparativa_modelos_123.csv - Métricas tabuladas\n\n")

cat("HALLAZGOS CLAVE:\n")
cat("1. Mejor modelo: CNN sin augmentation (92.71% val accuracy)\n")
cat("2. Mejora NET-1 → MLP:", 
    sprintf("%.2f%%", resultados_finales$Mejora_vs_NET1[2]), "\n")
cat("3. Mejora NET-1 → CNN sin aug:", 
    sprintf("%.2f%%", resultados_finales$Mejora_vs_NET1[3]), "\n")
cat("4. Impacto augmentation en CNN:", 
    sprintf("%.2f%%", 
            (resultados_finales$Val_Acc[3] - resultados_finales$Val_Acc[4]) * 100),
    "(degradación)\n\n")

cat("Gap de overfitting:\n")
for(i in 1:nrow(resultados_finales)) {
  cat(sprintf("  %s: %.2f%%\n", 
              resultados_finales$Modelo[i], 
              resultados_finales$Gap[i] * 100))
}

cat("\n=======================================================\n")
cat("Ubicación:", data_dir, "\n")
cat("=======================================================\n")
