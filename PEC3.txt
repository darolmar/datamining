# =============================================================================
# PRÁCTICA 3 - DEEP LEARNING: Clasificación de Granos de Polen
# Parte 1: Exploración y Análisis Exploratorio del Data
# =============================================================================

# 1. Instalación de paquetes necesarios (incluyendo keras3)
pacotes <- c("keras3", "tensorflow", "ggplot2", "gridExtra", "dplyr","tfdatasets","reshape2","caret")
new_packages <- pacotes[!(pacotes %in% installed.packages()[,"Package"])]
if(length(new_packages)) install.packages(new_packages, dependencies = TRUE)

# 2. Cargar librerías
library(keras3)
library(tensorflow)
library(ggplot2)
library(gridExtra)
library(dplyr, warn.conflicts = FALSE)
library(tfdatasets)
library(reshape2)
library(caret)

# 3. Configuración inicial (Solo si no lo has hecho antes)
#install_tensorflow()

# Configurar semilla para reproducibilidad
set.seed(123L)
tensorflow::tf$random$set_seed(123L)

# =============================================================================
# 1. CARGA Y ORGANIZACIÓN DEL DATASET
# =============================================================================

# Definir rutas al dataset
# AJUSTAR ESTAS RUTAS SEGÚN TU ESTRUCTURA DE CARPETAS
# data_dir <- "path/to/your/pollen_dataset"  # Carpeta principal
data_dir <- "/Users/darolmar/Desktop/anuka1200"  # Carpeta principal
class_a_dir <- file.path(data_dir, "TipoA_Kunzea")  # Primera especie
class_b_dir <- file.path(data_dir, "TipoB_Lepto")  # Segunda especie

# Listar archivos de imágenes
images_class_a <- list.files(class_a_dir, pattern = "\\.(jpg|jpeg|png)$", 
                             full.names = TRUE, ignore.case = TRUE)
images_class_b <- list.files(class_b_dir, pattern = "\\.(jpg|jpeg|png)$", 
                             full.names = TRUE, ignore.case = TRUE)

# Información básica del dataset
cat("=== INFORMACIÓN DEL DATASET ===\n")
cat("Imágenes Clase A:", length(images_class_a), "\n")
cat("Imágenes Clase B:", length(images_class_b), "\n")
cat("Total de imágenes:", length(images_class_a) + length(images_class_b), "\n")
cat("Balance de clases:", 
    round(length(images_class_a) / (length(images_class_a) + length(images_class_b)), 3), "\n\n")

# =============================================================================
# 2. ANÁLISIS DE DIMENSIONES Y CARACTERÍSTICAS
# =============================================================================

# Función para cargar una imagen y obtener sus dimensiones
get_image_info <- function(img_path) {
  img <- image_load(img_path, color_mode = "grayscale")
  img_array <- image_to_array(img)
  return(dim(img_array))
}

# Muestrear algunas imágenes para verificar dimensiones
sample_images <- c(head(images_class_a, 5), head(images_class_b, 5))
dimensions_list <- lapply(sample_images, get_image_info)

cat("=== DIMENSIONES DE LAS IMÁGENES ===\n")
print(dimensions_list[1:3])

# Verificar si todas tienen las mismas dimensiones
unique_dims <- unique(dimensions_list)
cat("\nNúmero de dimensiones únicas:", length(unique_dims), "\n")
if(length(unique_dims) == 1) {
  cat("✓ Todas las imágenes tienen dimensiones consistentes:", 
      paste(unique_dims[[1]], collapse = " x "), "\n\n")
} else {
  cat("⚠ ADVERTENCIA: Las imágenes tienen dimensiones variables\n")
  cat("Se requerirá redimensionamiento\n\n")
}

# =============================================================================
# 3. VISUALIZACIÓN DE MUESTRAS REPRESENTATIVAS
# =============================================================================

# Función para visualizar imágenes
plot_sample_images <- function(image_paths, class_name, n_samples = 6) {
  par(mfrow = c(2, 3), mar = c(1, 1, 2, 1))
  
  sample_indices <- sample(1:length(image_paths), min(n_samples, length(image_paths)))
  
  for(i in sample_indices) {
    img <- image_load(image_paths[i], color_mode = "grayscale", target_size = c(150, 150))
    img_array <- image_to_array(img)
    img_array <- img_array / 255  # Normalizar para visualización
    
    # Convertir a formato para plot
    img_matrix <- img_array[,,1]
    
    image(t(img_matrix[nrow(img_matrix):1,]), 
          col = gray.colors(256),
          axes = FALSE,
          main = paste(class_name, "-", i))
  }
  par(mfrow = c(1, 1))
}

cat("=== VISUALIZACIÓN DE MUESTRAS ===\n")
cat("Generando visualizaciones...\n\n")

# Visualizar Clase A
plot_sample_images(images_class_a, "Clase A", 6)
# Visualizar Clase B  
plot_sample_images(images_class_b, "Clase B", 6)

# =============================================================================
# 4. ANÁLISIS ESTADÍSTICO DE INTENSIDAD DE PÍXELES
# =============================================================================

# Función para calcular estadísticas de una imagen
get_pixel_stats <- function(img_path) {
  img <- image_load(img_path, color_mode = "grayscale", target_size = c(150, 150))
  img_array <- image_to_array(img) / 255
  
  return(data.frame(
    mean_intensity = mean(img_array),
    sd_intensity = sd(img_array),
    min_intensity = min(img_array),
    max_intensity = max(img_array)
  ))
}

# Calcular estadísticas para una muestra de cada clase
n_sample <- min(50, length(images_class_a), length(images_class_b))

cat("=== ANÁLISIS DE INTENSIDAD DE PÍXELES ===\n")
cat("Calculando estadísticas para", n_sample, "imágenes por clase...\n")

stats_a <- do.call(rbind, lapply(head(images_class_a, n_sample), get_pixel_stats))
stats_a$class <- "A"

stats_b <- do.call(rbind, lapply(head(images_class_b, n_sample), get_pixel_stats))
stats_b$class <- "B"

stats_combined <- rbind(stats_a, stats_b)

# Resumen estadístico por clase
cat("\nClase A - Estadísticas de intensidad:\n")
print(summary(stats_a[, 1:4]))

cat("\nClase B - Estadísticas de intensidad:\n")
print(summary(stats_b[, 1:4]))

# Visualización comparativa
p1 <- ggplot(stats_combined, aes(x = class, y = mean_intensity, fill = class)) +
  geom_boxplot() +
  labs(title = "Distribución de Intensidad Media por Clase",
       x = "Clase", y = "Intensidad Media") +
  theme_minimal() +
  scale_fill_manual(values = c("A" = "steelblue", "B" = "coral"))

p2 <- ggplot(stats_combined, aes(x = class, y = sd_intensity, fill = class)) +
  geom_boxplot() +
  labs(title = "Distribución de Desviación Estándar por Clase",
       x = "Clase", y = "Desviación Estándar") +
  theme_minimal() +
  scale_fill_manual(values = c("A" = "steelblue", "B" = "coral"))

grid.arrange(p1, p2, ncol = 2)

# =============================================================================
# 5. PREPARACIÓN DE METADATOS PARA MODELADO
# =============================================================================

# Crear dataframe con todas las rutas y etiquetas
all_images <- c(images_class_a, images_class_b)
all_labels <- c(rep(0, length(images_class_a)), 
                rep(1, length(images_class_b)))

metadata <- data.frame(
  image_path = all_images,
  label = all_labels,
  class_name = ifelse(all_labels == 0, "Clase_A", "Clase_B"),
  stringsAsFactors = FALSE
)

# Mezclar aleatoriamente
set.seed(123L)
metadata <- metadata[sample(nrow(metadata)), ]

cat("\n=== METADATA PREPARADO ===\n")
cat("Total de imágenes procesadas:", nrow(metadata), "\n")
cat("Distribución de etiquetas:\n")
print(table(metadata$class_name))

# =============================================================================
# 6. DIVISIÓN EN CONJUNTOS DE ENTRENAMIENTO, VALIDACIÓN Y TEST
# =============================================================================

# Proporción: 70% train, 15% validation, 15% test
n_total <- nrow(metadata)
n_train <- floor(0.70 * n_total)
n_val <- floor(0.15 * n_total)
n_test <- n_total - n_train - n_val

train_data <- metadata[1:n_train, ]
val_data <- metadata[(n_train + 1):(n_train + n_val), ]
test_data <- metadata[(n_train + n_val + 1):n_total, ]

cat("\n=== DIVISIÓN DE DATOS ===\n")
cat("Entrenamiento:", nrow(train_data), "imágenes\n")
cat("Validación:", nrow(val_data), "imágenes\n")
cat("Test:", nrow(test_data), "imágenes\n\n")

# Verificar balance en cada conjunto
cat("Balance en conjunto de entrenamiento:\n")
print(prop.table(table(train_data$class_name)))
cat("\nBalance en conjunto de validación:\n")
print(prop.table(table(val_data$class_name)))
cat("\nBalance en conjunto de test:\n")
print(prop.table(table(test_data$class_name)))

# =============================================================================
# 7. GUARDAR RESULTADOS DE LA EXPLORACIÓN
# =============================================================================

# Guardar metadata para uso posterior
saveRDS(list(
  train = train_data,
  val = val_data,
  test = test_data,
  img_dims = unique_dims[[1]]
), file.path(data_dir, "dataset_metadata.rds"))

cat("\n✓ Exploración completada. Metadata guardado en 'dataset_metadata.rds'\n")
cat("\n=== CONCLUSIONES DE LA EXPLORACIÓN ===\n")
cat("1. Dataset con", n_total, "imágenes en escala de grises\n")
cat("2. Balance de clases:", 
    ifelse(abs(length(images_class_a) - length(images_class_b)) < 10, 
           "equilibrado", "ligeramente desbalanceado"), "\n")
cat("3. Imágenes con dimensiones:", paste(unique_dims[[1]][1:2], collapse = "x"), "\n")
cat("4. Preparado para iniciar modelado\n")


# =============================================================================
# Parte 2: Modelado Progresivo (NET-1 → CNN Avanzadas) - ACTUALIZADO KERAS 3
# =============================================================================

# =============================================================================
# 1. CONFIGURACIÓN GLOBAL Y CARGA DE METADATA
# =============================================================================

metadata <- readRDS(file.path(data_dir,"dataset_metadata.rds"))

IMG_HEIGHT <- if(!is.null(metadata$img_dims[1])) as.integer(metadata$img_dims[1]) else 100L
IMG_WIDTH  <- if(!is.null(metadata$img_dims[2])) as.integer(metadata$img_dims[2]) else 100L
BATCH_SIZE <- 32L
EPOCHS <- 50L

train_data <- metadata$train
val_data <- metadata$val
test_data <- metadata$test


# =============================================================================
# 2. GENERADORES DE DATOS
# =============================================================================

# Normalización de los datos
normalization_layer <- layer_rescaling(scale = 1/255)

# Data Augmentation como una secuencia de capas
data_augmentation <- keras_model_sequential(layers = list(
  # 1. Rotación aleatoria: ±40° (40/360 = 0.111)
  # El factor en Keras 3 representa una fracción de 2pi
  layer_random_rotation(factor = 0.11, 
                        fill_mode = "nearest"),
  # 2. Desplazamiento horizontal y vertical: ±15%
  layer_random_translation(height_factor = 0.15, 
                           width_factor = 0.15, 
                           fill_mode = "nearest"),
  # 3. Zoom aleatorio: ±10%
  layer_random_zoom(height_factor = 0.10, 
                    width_factor = 0.10, 
                    fill_mode = "nearest"),
  # 4. Flip horizontal: Probabilidad 0.5
  layer_random_flip(mode = "horizontal")
))

# Definición del modelo usando una lista de capas
model <- keras_model_sequential(layers = list(
  # 1. Capa de entrada y normalización integrada
  layer_rescaling(scale = 1/255, input_shape = c(IMG_HEIGHT, IMG_WIDTH, 1L)),
  
  # 2. Primera capa convolucional
  layer_conv_2d(filters = 32L, kernel_size = c(3L, 3L), activation = "relu"),
  layer_max_pooling_2d(pool_size = c(2L, 2L)),
  
  # 3. Segunda capa convolucional
  layer_conv_2d(filters = 64L, kernel_size = c(3L, 3L), activation = "relu"),
  layer_max_pooling_2d(pool_size = c(2L, 2L)),
  
  # 4. Aplanado y capas densas
  layer_flatten(),
  layer_dense(units = 64L, activation = "relu"),
  layer_dense(units = 1L, activation = "sigmoid") # Sigmoid para clasificación binaria
))


# Aplicar transformaciones
# Dataset SIN aumentación
train_dataset_no_aug <- tensor_slices_dataset(list(
  train_data$image_path, 
  train_data$label
))
ds_train_no_aug <- dataset_map(train_dataset_no_aug, load_and_preprocess)
ds_train_no_aug <- dataset_map(ds_train_no_aug, function(img, label) {
  list(normalization_layer(img), label)
})
ds_train_no_aug <- dataset_batch(ds_train_no_aug, BATCH_SIZE)
train_dataset_no_aug <- dataset_prefetch(ds_train_no_aug, tensorflow::tf$data$AUTOTUNE)



#Dataset con aumentación
train_dataset_aug_base <- tensor_slices_dataset(list(
  train_data$image_path, 
  train_data$label
))
# 1. Función de carga: Convierte la ruta de archivo en un tensor de imagen
load_and_preprocess <- function(path, label) {
  img <- tensorflow::tf$io$read_file(path)
  img <- tensorflow::tf$image$decode_image(img, channels = 1L, expand_animations = FALSE)
  img <- tensorflow::tf$image$resize(img, size = c(IMG_HEIGHT, IMG_WIDTH))
  list(img, label)
}

# 2. Construcción del Dataset
# Paso A: Transformar rutas en imágenes (3D)
ds <- dataset_map(train_dataset_aug_base, load_and_preprocess)

# Paso B: Normalización simple (antes del batch)
ds <- dataset_map(ds, function(img, label) {
  list(normalization_layer(img), label)
})

# Paso C: Shuffle y BATCHING (Aquí los datos pasan a ser 4D automáticamente)
ds <- dataset_shuffle(ds, buffer_size = 1000L)
ds <- dataset_batch(ds, BATCH_SIZE)

# Paso D: APLICAR AUMENTACIÓN USANDO LAS CAPAS DIRECTAMENTE
# Extraemos las capas del modelo para usarlas de forma independiente
layers <- data_augmentation$layers

train_dataset_aug <- dataset_map(ds, function(img, label) {
  # Pasamos el lote de imágenes por cada transformación
  img_aug <- img
  for (layer in layers) {
    img_aug <- layer(img_aug, training = TRUE)
  }
  list(img_aug, label)
})

# Paso E: Prefetch
train_dataset_aug <- dataset_prefetch(train_dataset_aug, buffer_size = tensorflow::tf$data$AUTOTUNE)


#Dataset de validación
validation_dataset <- tensor_slices_dataset(list(
  val_data$image_path, 
  val_data$label
))
ds_val <- dataset_map(validation_dataset, load_and_preprocess)
ds_val <- dataset_map(ds_val, function(img, label) {
  list(normalization_layer(img), label)
})
ds_val <- dataset_batch(ds_val, BATCH_SIZE)
validation_dataset <- dataset_prefetch(ds_val, tensorflow::tf$data$AUTOTUNE)

#Dataset de test
test_dataset <- tensor_slices_dataset(list(
  test_data$image_path, 
  test_data$label
))
ds_test <- dataset_map(test_dataset, load_and_preprocess)
ds_test <- dataset_map(ds_test, function(img, label) {
  list(normalization_layer(img), label)
})
ds_test <- dataset_batch(ds_test, BATCH_SIZE)
test_dataset <- dataset_prefetch(ds_test, tensorflow::tf$data$AUTOTUNE)




cat("\n✓ Preparación de datasets completada\n")
n_train_no_aug <- as.numeric(tensorflow::tf$data$experimental$cardinality(train_dataset_no_aug))
n_train_aug <- as.numeric(tensorflow::tf$data$experimental$cardinality(train_dataset_aug))
n_val <- as.numeric(tensorflow::tf$data$experimental$cardinality(validation_dataset))
cat("\n=== CONCLUSIONES DE LA EXPLORACIÓN ===\n")
cat("Número de elementos:\n")
cat("- Entrenamiento (sin aug):", n_train_no_aug, "\n")
cat("- Entrenamiento (con aug):", n_train_aug, "\n")
cat("- Validación:            ", n_val, "\n")

# =============================================================================
# 3. VISUALIZAR AUGMENTATION (ACTUALIZADO)
# =============================================================================

visualize_augmentation <- function(dataset, n_samples = 9) {
  batch <- dataset %>% tfdatasets::dataset_take(1) %>% as_iterator() %>% iter_next()
  images <- batch[[1]]
  
  par(mfrow = c(3, 3), mar = c(1, 1, 2, 1))
  for(i in 1:min(n_samples, dim(images)[1])) {
    img_display <- as.array(images[i,,,1])
    image(t(img_display[nrow(img_display):1,]), 
          col = gray.colors(256), axes = FALSE,
          main = paste("Augmented", i))
  }
  par(mfrow = c(1, 1))
}

visualize_augmentation(train_dataset_aug)

# =============================================================================
# 4. MODELO 1: NET-1 (REGRESIÓN LOGÍSTICA)
# =============================================================================

model_1 <- keras_model_sequential(input_shape = c(IMG_HEIGHT, IMG_WIDTH, 1))
model_1 <- layer_flatten(model_1)
model_1 <- layer_dense(model_1, units = 64, activation = "relu")
model_1 <- layer_dense(model_1, units = 32, activation = "relu")
model_1 <- layer_dense(model_1, units = 1, activation = "sigmoid")
compile(
  model_1,
  optimizer = "adam",
  loss = "binary_crossentropy",
  metrics = list("accuracy")
)
history_1 <- model_1 %>% fit(train_dataset_no_aug, epochs = EPOCHS, validation_data = validation_dataset, verbose = 2)

save_model(model_1, file.path(data_dir, "model_1_net1.keras"), overwrite = TRUE)
saveRDS(history_1, file.path(data_dir, "history_1.rds"))


# =============================================================================
# 5. MODELO 2: RED CON CAPAS OCULTAS
# =============================================================================

# Modelo 2 corregido
model_2 <- keras_model_sequential() %>%
  layer_flatten(input_shape = c(IMG_HEIGHT, IMG_WIDTH, 1)) %>%
  layer_dense(units = 256L, activation = "relu") %>% # <-- Asegúrate de que este %>% esté ahí
  layer_dropout(rate = 0.3) %>%                      # <-- ¡AQUÍ suele faltar el %>%!
  layer_dense(units = 1L, activation = "sigmoid")    # Capa final

model_2 %>% compile(optimizer = optimizer_adam(), loss = "binary_crossentropy", metrics = "accuracy")

history_2 <- model_2 %>% fit(train_dataset_no_aug, epochs = EPOCHS, validation_data = validation_dataset, verbose = 2)

save_model(model_2, file.path(data_dir, "model_2_mlp.keras"), overwrite = TRUE)
saveRDS(history_2, file.path(data_dir, "history_2.rds"))



# =============================================================================
# 6. MODELO 3: CNN BASE (CON AUGMENTATION)
# =============================================================================

model_3 <- keras_model_sequential() %>%
  layer_conv_2d(filters = 32, kernel_size = c(3, 3), activation = "relu", input_shape = c(IMG_HEIGHT, IMG_WIDTH, 1)) %>%
  layer_max_pooling_2d() %>%
  layer_conv_2d(filters = 64, kernel_size = c(3, 3), activation = "relu") %>%
  layer_max_pooling_2d() %>%
  layer_flatten() %>%
  layer_dense(units = 128, activation = "relu") %>%
  layer_dense(units = 1, activation = "sigmoid")

model_3 %>% compile(optimizer = optimizer_adam(), loss = "binary_crossentropy", metrics = "accuracy")
save_model(model_3, file.path(data_dir, "model_3_cnn_base.keras"), overwrite = TRUE)

history_3 <- model_3 %>% fit(train_dataset_aug, epochs = EPOCHS, validation_data = validation_dataset, verbose = 2)
saveRDS(history_3, file.path(data_dir, "history_3.rds"))

# MODELO 3b: CNN Base SIN AUGMENTATION (para comparación)
model_3_no_aug <- keras_model_sequential() %>%
  layer_conv_2d(filters = 32, kernel_size = c(3, 3), activation = "relu", 
                input_shape = c(IMG_HEIGHT, IMG_WIDTH, 1)) %>%
  layer_max_pooling_2d() %>%
  layer_conv_2d(filters = 64, kernel_size = c(3, 3), activation = "relu") %>%
  layer_max_pooling_2d() %>%
  layer_flatten() %>%
  layer_dense(units = 128, activation = "relu") %>%
  layer_dense(units = 1, activation = "sigmoid")

model_3_no_aug %>% compile(
  optimizer = optimizer_adam(), 
  loss = "binary_crossentropy", 
  metrics = "accuracy"
)

history_3_no_aug <- model_3_no_aug %>% fit(
  train_dataset_no_aug,  # ← SIN augmentation
  epochs = EPOCHS, 
  validation_data = validation_dataset, 
  verbose = 2
)

saveRDS(history_3_no_aug, file.path(data_dir, "history_3_no_aug.rds"))

# =============================================================================
# 7. MODELO 4: CNN CON BATCH NORMALIZATION
# =============================================================================

model_4  <- keras_model_sequential() %>%
  layer_conv_2d(32, c(3,3), activation = "relu", 
                input_shape = c(IMG_HEIGHT, IMG_WIDTH, 1)) %>%
  layer_batch_normalization() %>%
  layer_max_pooling_2d() %>%
  
  layer_conv_2d(64, c(3,3), activation = "relu") %>%
  layer_batch_normalization() %>%
  layer_max_pooling_2d() %>%
  
  layer_conv_2d(128, c(3,3), activation = "relu") %>%
  layer_batch_normalization() %>%
  layer_max_pooling_2d() %>%
  
  layer_flatten() %>%
  layer_dense(128, activation = "relu") %>%
  layer_dropout(0.5) %>%
  layer_dense(1, activation = "sigmoid")

model_4 %>% compile(
  optimizer = optimizer_adam(learning_rate = 0.0001),  # LR 10x menor
  loss = "binary_crossentropy", 
  metrics = "accuracy"
)

history_4 <- model_4 %>% fit(
  train_dataset_aug,
  epochs = EPOCHS,
  validation_data = validation_dataset,
  verbose = 2
)
save_model(model_4, file.path(data_dir, "model_4.keras"), overwrite = TRUE)
saveRDS(history_4, file.path(data_dir, "history_4.rds"))


# =============================================================================
# 8. MODELO 5: CNN CON GAP
# =============================================================================

model_5 <- keras_model_sequential() %>%
  layer_conv_2d(32, c(5,5), activation = "relu",  # Kernel 5x5
                input_shape = c(IMG_HEIGHT, IMG_WIDTH, 1)) %>%
  layer_max_pooling_2d() %>%
  layer_dropout(0.25) %>%
  
  layer_conv_2d(64, c(3,3), activation = "relu") %>%
  layer_max_pooling_2d() %>%
  layer_dropout(0.25) %>%
  
  layer_conv_2d(128, c(3,3), activation = "relu") %>%
  layer_max_pooling_2d() %>%
  layer_dropout(0.25) %>%
  
  layer_flatten() %>%
  layer_dense(256, activation = "relu") %>%
  layer_dropout(0.5) %>%
  layer_dense(128, activation = "relu") %>%
  layer_dropout(0.5) %>%
  layer_dense(1, activation = "sigmoid")

model_5 %>% compile(
  optimizer = optimizer_adam(learning_rate = 0.0001),
  loss = "binary_crossentropy", 
  metrics = "accuracy"
)

history_5 <- model_5 %>% fit(
  train_dataset_aug,
  epochs = EPOCHS,
  validation_data = validation_dataset,
  verbose = 2
)
save_model(model_5, file.path(data_dir, "model_5.keras"), overwrite = TRUE)
saveRDS(history_5, file.path(data_dir, "history_5.rds"))


# =============================================================================
# 9. COMPARACIÓN FINAL
# =============================================================================

# Función para contar parámetros
count_params <- function(model) {
  total_params <- sum(sapply(model$trainable_weights, function(w) {
    prod(dim(w))
  }))
  return(total_params)
}

# Contar parámetros de cada modelo
params_1 <- count_params(model_1)
params_2 <- count_params(model_2)
params_3 <- count_params(model_3)
params_4 <- count_params(model_4)
params_5 <- count_params(model_5)

# Función para calcular F1-score
calculate_f1 <- function(model, dataset) {
  
  # 1. Obtener predicciones (probabilidades)
  predictions_prob <- predict(object = model, x = dataset, verbose = 0)
  predictions_class <- ifelse(predictions_prob > 0.5, 1, 0)
  
  # 2. Extraer etiquetas verdaderas directamente del dataset
  # Esto garantiza que el orden sea idéntico al de las predicciones
  true_labels <- c()
  it <- as_iterator(dataset)
  
  while (TRUE) {
    batch <- iter_next(it)
    if (is.null(batch)) break
    
    # El label suele estar en la segunda posición de la lista del batch: list(inputs, labels)
    labels_vec <- as.array(batch[[2]])
    true_labels <- c(true_labels, labels_vec)
  }
  
  # 3. Calcular Matriz de Confusión y F1-Score con caret
  cm <- confusionMatrix(
    data = factor(predictions_class, levels = c(0, 1)),
    reference = factor(true_labels, levels = c(0, 1)),
    positive = "1"
  )
  
  # Extraer la métrica F1
  f1_score <- cm$byClass["F1"]
  
  # Limpiar nombres para devolver solo el valor numérico
  return(as.numeric(f1_score))
}
cat("\n=== EVALUANDO EN CONJUNTO DE VALIDACIÓN ===\n")

# Evaluación del modelo 1 en el dataset de validación y de test
eval_1_val <- evaluate(
  object = model_1,
  x = validation_dataset
)
eval_1_test <- evaluate(
  object = model_1,
  x = test_dataset
)

# Evaluación del modelo 2 en el dataset de validación y de test
eval_2_val <- evaluate(
  object = model_2,
  x = validation_dataset
)
eval_2_test <- evaluate(
  object = model_2,
  x = test_dataset
)

# Evaluación del modelo 3 en el dataset de validación y de test
eval_3_val <- evaluate(
  object = model_3,
  x = validation_dataset
)
eval_3_test <- evaluate(
  object = model_3,
  x = test_dataset
)

# Evaluación del modelo 1 en el dataset de validación y de test
eval_4_val <- evaluate(
  object = model_4,
  x = validation_dataset
)
eval_4_test <- evaluate(
  object = model_4,
  x = test_dataset
)

# Evaluación del modelo 5 en el dataset de validación y de test
eval_5_val <- evaluate(
  object = model_5,
  x = validation_dataset
)
eval_5_test <- evaluate(
  object = model_5,
  x = test_dataset
)

results_val <- data.frame(
  Modelo = c("NET-1", "MLP", "CNN Base", "CNN + BN", "CNN + GAP"),
  Val_Accuracy = c(
    eval_1_val[["accuracy"]],
    eval_2_val[["accuracy"]],
    eval_3_val[["accuracy"]],
    eval_4_val[["accuracy"]],
    eval_5_val[["accuracy"]]
  ),
  Val_Loss = c(
    eval_1_val[["loss"]],
    eval_2_val[["loss"]],
    eval_3_val[["loss"]],
    eval_4_val[["loss"]],
    eval_5_val[["loss"]]
  )
)

cat("\n--- RESULTADOS SOBRE VALIDACIÓN ---\n")
print(results_val)

# Calcular F1-scores
cat("\n=== CALCULANDO F1-SCORES EN TEST ===\n")

f1_1 <- calculate_f1(model_1, test_data)
cat("Modelo 1 - F1 Score:", f1_1, "\n")

f1_2 <- calculate_f1(model_2, test_data)
cat("Modelo 2 - F1 Score:", f1_2, "\n")

f1_3 <- calculate_f1(model_3, test_data)
cat("Modelo 3 - F1 Score:", f1_3, "\n")

f1_4 <- calculate_f1(model_4, test_data)
cat("Modelo 4 - F1 Score:", f1_4, "\n")

f1_5 <- calculate_f1(model_5, test_data)
cat("Modelo 5 - F1 Score:", f1_5, "\n")

# =============================================================================
# TABLA 2: Consolidar resultados
# =============================================================================

tabla_2 <- data.frame(
  Modelo = c("NET-1", "Modelo 2", "Modelo 3", "Modelo 4", "Modelo 5"),
  Arquitectura = c(
    "Logistic Regression",
    "MLP (2 capas ocultas)",
    "CNN Base",
    "CNN + Batch Norm",
    "CNN + Dropout + Aug"
  ),
  Parametros = c(params_1, params_2, params_3, params_4, params_5),
  Val_Accuracy = c(
    eval_1_val["accuracy"],
    eval_2_val["accuracy"],
    eval_3_val["accuracy"],
    eval_4_val["accuracy"],
    eval_5_val["accuracy"]
  ),
  Val_Loss = c(
    eval_1_val["loss"],
    eval_2_val["loss"],
    eval_3_val["loss"],
    eval_4_val["loss"],
    eval_5_val["loss"]
  ),
  Test_Accuracy = c(
    eval_1_test["accuracy"],
    eval_2_test["accuracy"],
    eval_3_test["accuracy"],
    eval_4_test["accuracy"],
    eval_5_test["accuracy"]
  ),
  Test_F1_Score = c(f1_1, f1_2, f1_3, f1_4, f1_5)
)

# Redondear valores
tabla_2$Val_Accuracy <- round(tabla_2$Val_Accuracy, 4)
tabla_2$Val_Loss <- round(tabla_2$Val_Loss, 4)
tabla_2$Test_Accuracy <- round(tabla_2$Test_Accuracy, 4)
tabla_2$Test_F1_Score <- round(tabla_2$Test_F1_Score, 4)

cat("\n=== TABLA 2: MÉTRICAS DE DESEMPEÑO COMPARATIVO ===\n")
print(tabla_2)

# Guardar resultados
saveRDS(tabla_2, file.path(data_dir, "tabla_2_metricas_desempeno.rds"))
write.csv(tabla_2, file.path(data_dir, "tabla_2_metricas_desempeno.csv"), row.names = FALSE)

# Función para extraer datos de historia
extract_history_data <- function(history, model_name) {
  epochs <- seq_along(history$metrics$loss)
  
  df <- data.frame(
    epoch = rep(epochs, 4),
    value = c(
      history$metrics$accuracy,
      history$metrics$val_accuracy,
      history$metrics$loss,
      history$metrics$val_loss
    ),
    metric = rep(c("Train Accuracy", "Val Accuracy", "Train Loss", "Val Loss"), 
                 each = length(epochs)),
    model = model_name
  )
  
  return(df)
}

# Extraer datos de todos los modelos
df_1 <- extract_history_data(history_1, "NET-1")
df_2 <- extract_history_data(history_2, "MLP")
df_3 <- extract_history_data(history_3, "CNN Base")
df_4 <- extract_history_data(history_4, "CNN BN")
df_5 <- extract_history_data(history_5, "CNN GAP")

# Combinar todos los datos
df_all <- rbind(df_1, df_2, df_3, df_4, df_5)
df_all$model <- factor(df_all$model, 
                       levels = c("NET-1", "MLP", "CNN Base", "CNN BN", "CNN GAP"))

# Separar accuracy y loss
df_accuracy <- df_all %>% filter(metric %in% c("Train Accuracy", "Val Accuracy"))
df_loss <- df_all %>% filter(metric %in% c("Train Loss", "Val Loss"))

# Configurar colores y estilos
model_colors <- c("NET-1" = "#E41A1C", "MLP" = "#377EB8", "CNN Base" = "#4DAF4A",
                  "CNN BN" = "#984EA3", "CNN GAP" = "#FF7F00")

# Plot de Accuracy
p_accuracy <- ggplot(df_accuracy, aes(x = epoch, y = value, color = model, linetype = metric)) +
  geom_line(linewidth = 0.8) +
  scale_color_manual(values = model_colors) +
  scale_linetype_manual(values = c("Train Accuracy" = "solid", "Val Accuracy" = "dashed")) +
  labs(
    title = "Evolución de Accuracy durante el Entrenamiento",
    x = "Época",
    y = "Accuracy",
    color = "Modelo",
    linetype = "Conjunto"
  ) +
  theme_minimal() +
  theme(
    legend.position = "right",
    plot.title = element_text(hjust = 0.5, face = "bold", size = 12),
    axis.title = element_text(size = 10),
    legend.text = element_text(size = 8),
    legend.title = element_text(size = 9, face = "bold")
  ) +
  ylim(0.45, 1.0)

# Plot de Loss
p_loss <- ggplot(df_loss, aes(x = epoch, y = value, color = model, linetype = metric)) +
  geom_line(linewidth = 0.8) +
  scale_color_manual(values = model_colors) +
  scale_linetype_manual(values = c("Train Loss" = "solid", "Val Loss" = "dashed")) +
  labs(
    title = "Evolución de Pérdida (Loss) durante el Entrenamiento",
    x = "Época",
    y = "Binary Cross-Entropy Loss",
    color = "Modelo",
    linetype = "Conjunto"
  ) +
  theme_minimal() +
  theme(
    legend.position = "right",
    plot.title = element_text(hjust = 0.5, face = "bold", size = 12),
    axis.title = element_text(size = 10),
    legend.text = element_text(size = 8),
    legend.title = element_text(size = 9, face = "bold")
  ) +
  ylim(0, 1.2)

# Combinar ambos plots
p_combined <- grid.arrange(p_accuracy, p_loss, ncol = 1)

ggsave(file.path(data_dir, file.path(data_dir, "figura_curvas_aprendizaje.png")), plot = p_combined, 
       width = 10, height = 10, dpi = 300)

cat("\n✓ Figura 4 generada: 'figura4_curvas_aprendizaje.png'\n")

# =============================================================================
# Análisis cuantitativo del overfitting
# =============================================================================

# Calcular brecha train-val al final del entrenamiento
calculate_gap <- function(history) {
  final_train_acc <- tail(history$metrics$accuracy, 1)
  final_val_acc <- tail(history$metrics$val_accuracy, 1)
  gap <- final_train_acc - final_val_acc
  return(gap)
}

overfitting_gaps <- data.frame(
  Modelo = c("NET-1", "MLP", "CNN Base", "CNN + BatchNorm", "CNN + Dropout + Aug"),
  Gap = c(
    calculate_gap(history_1),
    calculate_gap(history_2),
    calculate_gap(history_3),
    calculate_gap(history_4),
    calculate_gap(history_5)
  )
)

cat("\n=== ANÁLISIS DE BRECHA TRAIN-VAL (OVERFITTING) ===\n")
print(overfitting_gaps)
cat("\nInterpretación: Brechas menores indican mejor generalización.\n")

# =============================================================================
# MATRICES DE CONFUSIÓN Y MÉTRICAS ADICIONALES
# =============================================================================

# Función para calcular métricas detalladas
calculate_detailed_metrics <- function(model, dataset) {
  
  # 1. Obtener predicciones (Keras 3 maneja el dataset automáticamente)
  # Devuelve probabilidades (sigmoid)
  predictions_prob <- predict(model, dataset)
  predictions_class <- ifelse(predictions_prob > 0.5, 1, 0)
  
  # 2. Extraer etiquetas reales del dataset para garantizar alineación absoluta
  # Iteramos el dataset para recolectar los labels (y)
  true_labels <- c()
  it <- as_iterator(dataset)
  while (TRUE) {
    batch <- iter_next(it)
    if (is.null(batch)) break
    # batch[[2]] son las etiquetas. Convertimos de tensor a vector R.
    labels_vec <- as.array(batch[[2]])
    true_labels <- c(true_labels, labels_vec)
  }
  
  # 3. Matriz de confusión con caret
  cm <- confusionMatrix(
    factor(predictions_class, levels = c(0, 1)),
    factor(true_labels, levels = c(0, 1)),
    positive = "1"
  )
  
  return(list(
    confusion_matrix = cm$table,
    accuracy = cm$overall["Accuracy"],
    precision = cm$byClass["Precision"],
    recall = cm$byClass["Recall"],
    specificity = cm$byClass["Specificity"],
    f1 = cm$byClass["F1"]
  ))
}

# Calcular métricas (usando el objeto test_dataset que creamos previamente)
metrics_1 <- calculate_detailed_metrics(model_1, test_dataset)
metrics_2 <- calculate_detailed_metrics(model_2, test_dataset)
metrics_3 <- calculate_detailed_metrics(model_3, test_dataset)
metrics_4 <- calculate_detailed_metrics(model_4, test_dataset)
metrics_5 <- calculate_detailed_metrics(model_5, test_dataset)

# Consolidar resultados en Dataframe
detailed_results <- data.frame(
  Modelo = c("NET-1", "MLP", "CNN Base", "CNN BN", "CNN GAP"),
  Accuracy = c(metrics_1$accuracy, metrics_2$accuracy, metrics_3$accuracy, 
               metrics_4$accuracy, metrics_5$accuracy),
  Precision = c(metrics_1$precision, metrics_2$precision, metrics_3$precision, 
                metrics_4$precision, metrics_5$precision),
  Recall = c(metrics_1$recall, metrics_2$recall, metrics_3$recall, 
             metrics_4$recall, metrics_5$recall),
  Specificity = c(metrics_1$specificity, metrics_2$specificity, metrics_3$specificity, 
                  metrics_4$specificity, metrics_5$specificity),
  F1_Score = c(metrics_1$f1, metrics_2$f1, metrics_3$f1, metrics_4$f1, metrics_5$f1)
)

print(detailed_results)
saveRDS(detailed_results, "detailed_metrics.rds")

plot_confusion_matrix <- function(cm, title) {
  cm_df <- as.data.frame(cm)
  colnames(cm_df) <- c("Prediccion", "Real", "Frecuencia")
  
  ggplot(cm_df, aes(x = Real, y = Prediccion, fill = Frecuencia)) +
    geom_tile() +
    geom_text(aes(label = Frecuencia), size = 6, color = "white", fontface = "bold") +
    scale_fill_gradient(low = "steelblue", high = "darkred") +
    labs(title = title, x = "Clase Real", y = "Clase Predicha") +
    theme_minimal() +
    theme(
      plot.title = element_text(hjust = 0.5, face = "bold"),
      axis.text = element_text(size = 10)
    )
}

p_cm1 <- plot_confusion_matrix(metrics_1$confusion_matrix, "NET-1")
p_cm2 <- plot_confusion_matrix(metrics_2$confusion_matrix, "MLP")
p_cm3 <- plot_confusion_matrix(metrics_3$confusion_matrix, "CNN Base")
p_cm4 <- plot_confusion_matrix(metrics_4$confusion_matrix, "CNN BN")
p_cm5 <- plot_confusion_matrix(metrics_5$confusion_matrix, "CNN GAP")

# Organizar en rejilla y guardar
p_cm_all <- grid.arrange(p_cm1, p_cm2, p_cm3, p_cm4, p_cm5, ncol = 3)
ggsave(file.path(data_dir, "figura5_confusion_matrices.png"), plot = p_cm_all, width = 14, height = 10, dpi = 300)

# Consolidar Tabla 3
tabla_3 <- rbind(metrics_1, metrics_2, metrics_3, metrics_4, metrics_5)

cat("\n=== TABLA 3: MATRICES DE CONFUSIÓN Y MÉTRICAS DETALLADAS ===\n")
print(tabla_3)

# =============================================================================
# VISUALIZACIÓN DE FILTROS CONVOLUCIONALES
# =============================================================================

# 1. Función para extraer pesos (robusta)
extract_conv_weights <- function(model, layer_name) {
  layer <- get_layer(model, layer_name)
  weights <- get_weights(layer)
  return(weights[[1]]) # El elemento 1 son los kernels/filtros
}

# 2. Identificación dinámica de capas
# Esto evita el error "No such layer" al buscar los nombres reales
conv_layer_names <- c()
for (layer in model_3$layers) {
  if (grepl("conv2d", layer$name)) {
    conv_layer_names <- c(conv_layer_names, layer$name)
  }
}

cat("Capas convolucionales detectadas:", paste(conv_layer_names, collapse = ", "), "\n")

# 3. Función de visualización optimizada
plot_conv_filters <- function(filters, n_filters = 32, title = "Filtros") {
  dims <- dim(filters)
  # dims[1]: height, dims[2]: width, dims[3]: in_channels, dims[4]: out_channels
  n_channels <- dims[3]
  total_out <- dims[4]
  n_to_plot <- min(n_filters, total_out)
  
  # Configurar rejilla
  side <- ceiling(sqrt(n_to_plot))
  par(mfrow = c(side, side), 
      mar = c(0.1, 0.1, 1.2, 0.1), 
      oma = c(0, 0, 3, 0))
  
  for (i in 1:n_to_plot) {
    if (n_channels == 1) {
      # Primera capa (Blanco y negro / 1 canal)
      img <- filters[, , 1, i]
    } else {
      # Capas profundas (Promediamos canales de entrada)
      img <- apply(filters[, , , i], c(1, 2), mean)
    }
    
    # Normalización para contraste visual
    img <- (img - min(img)) / (max(img) - min(img) + 1e-7)
    
    # Dibujar
    image(t(img[nrow(img):1, ]), 
          col = gray.colors(256), 
          axes = FALSE, 
          main = paste(i), 
          cex.main = 0.6)
    box(col = "gray70")
  }
  mtext(title, outer = TRUE, cex = 1.2, font = 2)
}

# 4. Bucle de generación automática de imágenes
# Este bloque recorre todas las capas detectadas y guarda una imagen por capa
for (i in seq_along(conv_layer_names)) {
  layer_name <- conv_layer_names[i]
  filters <- extract_conv_weights(model_3, layer_name)
  
  filename <- paste0("figura6_filtros_", layer_name, ".png")
  full_path <- file.path(data_dir, filename)  
  png(full_path, width = 1200, height = 1200, res = 150)
  plot_conv_filters(filters, 
                    n_filters = 32, 
                    title = paste("Capa:", layer_name, "- Filtros extraídos"))
  dev.off()
  
  cat("✓ Guardada visualización para:", layer_name, "en", full_path, "\n")
}

# 5. Análisis estadístico (Consolidado)
filter_stats_list <- list()

for (name in conv_layer_names) {
  f <- extract_conv_weights(model_3, name)
  f_means <- apply(f, 4, mean)
  f_sds <- apply(f, 4, sd)
  
  df_temp <- data.frame(
    layer = name,
    mean_weight = mean(f_means),
    sd_weight = mean(f_sds)
  )
  filter_stats_list[[name]] <- df_temp
}

filter_stats_final <- do.call(rbind, filter_stats_list)
print(filter_stats_final)
saveRDS(filter_stats_final, file.path(data_dir, "filter_statistics.rds"))

cat("\n✓ Visualización y análisis completados.\n")

# =============================================================================
# 3. VISUALIZACIÓN DE MAPAS DE CARACTERÍSTICAS (Feature Maps)
# =============================================================================

cat("=== MAPAS DE CARACTERÍSTICAS ===\n")
#Cargamos el modelo
model_cnn <- model_3

# Cargar metadata y seleccionar una imagen de test
metadata <- readRDS(file.path(data_dir,"dataset_metadata.rds"))
test_data <- metadata$test

# Seleccionar una imagen de cada clase para análisis
sample_class_a <- test_data %>% filter(label == 0) %>% slice(1)
sample_class_b <- test_data %>% filter(label == 1) %>% slice(1)

# Función para extraer mapas de características
get_feature_maps <- function(model, image_path, layer_indices) {
  # 1. Cargar y preparar la imagen
  img <- image_load(image_path, target_size = c(IMG_HEIGHT, IMG_WIDTH), color_mode = "grayscale")
  img_array <- image_to_array(img)
  img_array <- array_reshape(img_array, c(1, IMG_HEIGHT, IMG_WIDTH, 1))
  img_array <- img_array / 255 # Normalización manual
  
  # 2. Extraer las salidas de las capas deseadas
  # Cambiamos 'model$input' por 'model$inputs' para Keras 3
  layer_outputs <- lapply(layer_indices, function(i) model$layers[[i]]$output)
  
  # 3. Crear un modelo intermedio que devuelva los mapas de características
  activation_model <- keras_model(inputs = model$inputs, outputs = layer_outputs)
  
  # 4. Obtener las activaciones
  activations <- predict(activation_model, img_array)
  
  return(activations)
}

# Extraer feature maps para una imagen de Clase A
cat("Extrayendo feature maps para Clase A...\n")
# 1. Asegurar que las dimensiones son enteros (L)
img_size_dims <- c(1L, IMG_HEIGHT, IMG_WIDTH, 1L) 

# 3. Crear un tensor de prueba y pasarlo por el modelo 
# Usamos predict() porque es la forma más oficial de 'llamar' al modelo
dummy_data <- array(0, dim = img_size_dims)
predict(model_cnn, dummy_data) 

# 4. Ahora intenta de nuevo la extracción
feature_maps_a <- get_feature_maps(model_cnn, 
                                   sample_class_a$image_path, 
                                   layer_indices = c(1, 3, 5))

# Función para visualizar feature maps de una capa
plot_feature_maps <- function(activation, layer_name, n_features = 16, ncol = 4) {
  n_features <- min(n_features, dim(activation)[4])
  nrow <- ceiling(n_features / ncol)
  
  par(mfrow = c(nrow, ncol), mar = c(0.5, 0.5, 1.5, 0.5))
  
  for(i in 1:n_features) {
    feature <- activation[1,,,i]
    
    # Normalizar para visualización
    feature <- (feature - min(feature)) / (max(feature) - min(feature))
    
    image(t(feature[nrow(feature):1,]), 
          col = gray.colors(256),
          axes = FALSE,
          main = paste(layer_name, "- Map", i),
          cex.main = 0.7)
  }
  par(mfrow = c(1, 1))
}

# Visualizar mapas de la primera capa convolucional
png(file.path(data_dir, "figura7_feature_maps_conv1.png"), width = 2000, height = 2000, res = 300)
plot_feature_maps(feature_maps_a[[1]], "Conv1 (32 filtros)", 
                  n_features = 16, ncol = 4)
dev.off()

# Visualizar mapas de la segunda capa convolucional
png(file.path(data_dir, "figura7_feature_maps_conv2.png"), width = 2000, height = 2000, res = 300)

plot_feature_maps(feature_maps_a[[2]], "Conv2 (64 filtros)", 
                  n_features = 16, ncol = 4)
dev.off()

# Visualizar mapas de la tercera capa convolucional
png(file.path(data_dir, "figura7_feature_maps_conv3.png"), width = 2000, height = 2000, res = 300)

plot_feature_maps(feature_maps_a[[3]], "Conv3 (128 filtros)", 
                  n_features = 16, ncol = 4)
dev.off()

cat("✓ Feature maps generados para todas las capas convolucionales\n\n")

# =============================================================================
# 4. COMPARACIÓN DE FEATURE MAPS: Clase A vs Clase B
# =============================================================================

cat("Extrayendo feature maps para Clase B (comparación)...\n")

# Extraer usando la función que ya adaptamos para Keras 3
feature_maps_b <- get_feature_maps(model_cnn, 
                                   sample_class_b$image_path, 
                                   layer_indices = c(1, 3, 5))

# Visualización comparativa: misma capa, ambas clases
# Guardamos en el directorio data_path definido anteriormente
png(file.path(data_dir, "figura_comparacion_clases_feature_maps.png"), width = 3000, height = 1500, res = 300)
par(mfrow = c(2, 8), mar = c(0.5, 0.5, 1.5, 0.5))

# --- Primera fila: Clase A ---
# Usamos [[1]] directamente, que corresponde a la primera capa solicitada
for(i in 1:8) {
  # Acceso directo al tensor: [batch, alto, ancho, canal]
  feature_a <- feature_maps_a[[1]][1, , , i]
  
  # Normalización segura (+ 1e-8 evita el error de Inf si el mapa está vacío)
  f_min <- min(feature_a)
  f_max <- max(feature_a)
  feature_a <- (feature_a - f_min) / (f_max - f_min + 1e-8)
  
  image(t(feature_a[nrow(feature_a):1, ]), 
        col = gray.colors(256), 
        axes = FALSE, 
        main = paste("Clase A - F", i), 
        cex.main = 0.7)
}

# --- Segunda fila: Clase B ---
for(i in 1:8) {
  # Acceso directo al tensor
  feature_b <- feature_maps_b[[1]][1, , , i]
  
  # Normalización segura
  f_min <- min(feature_b)
  f_max <- max(feature_b)
  feature_b <- (feature_b - f_min) / (f_max - f_min + 1e-8)
  
  image(t(feature_b[nrow(feature_b):1, ]), 
        col = gray.colors(256), 
        axes = FALSE, 
        main = paste("Clase B - F", i), 
        cex.main = 0.7)
}

par(mfrow = c(1, 1))
dev.off()

cat("✓ Comparación de feature maps guardada en figura_comparacion_clases_feature_maps.png\n")

# =============================================================================
# 5. TABLA RESUMEN DE RESULTADOS FINALES
# =============================================================================

cat("=== TABLA RESUMEN FINAL ===\n\n")

# Cargar todos los historiales
histories <- list(history_1, history_2, history_3, history_4, history_5)
model_names <- c("NET-1", "MLP", "CNN Base", "CNN + BN", "CNN + GAP")

# Calcular métricas finales
final_results <- data.frame(
  Modelo = model_names,
  Params = c(10001, 3383873, 2473729, 2530753, 558721),  # Aproximado, ajustar
  Train_Acc = sapply(histories, function(h) round(tail(h$metrics$accuracy, 1), 4)),
  Val_Acc = sapply(histories, function(h) round(tail(h$metrics$val_accuracy, 1), 4)),
  Train_Loss = sapply(histories, function(h) round(tail(h$metrics$loss, 1), 4)),
  Val_Loss = sapply(histories, function(h) round(tail(h$metrics$val_loss, 1), 4)),
  Gap = sapply(histories, function(h) {
    round(tail(h$metrics$accuracy, 1) - tail(h$metrics$val_accuracy, 1), 4)
  })
)

print(final_results)

# Guardar tabla en CSV para incluir en memoria
write.csv(
  final_results, 
  file = file.path(data_dir, "tabla_resultados_finales.csv"), 
  row.names = FALSE
)
# Identificar mejor modelo
best_model_idx <- which.max(final_results$Val_Acc)
cat("\n✓ MEJOR MODELO:", model_names[best_model_idx], "\n")
cat("  - Val Accuracy:", final_results$Val_Acc[best_model_idx], "\n")
cat("  - Gap (overfitting):", final_results$Gap[best_model_idx], "\n\n")
